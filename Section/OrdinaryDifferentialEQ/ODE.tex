\documentclass[../main.tex]{subfiles}
\begin{document}
\subsection*{First Order}
\subsubsection*{First Order ODE.} Written in the form
\begin{equation*}
    y'+P(x)y=Q(x)
\end{equation*}
where $P$ and $Q$ are functions of $x$ has the solution
\begin{align*}
    ye^I&=\int Q e^I\;dx+c\\
    y&=e^{-I}\int Q e^I\;dx+ce^{-I}
\end{align*}
where\begin{equation*}
    I=\int P\;dx
\end{equation*}

\subsubsection*{Bernoulli Equation.} The differential equation
\begin{align*}
    y'+P(x)y=Q(x)y^n
\end{align*}
where $P$ and $Q$ are functions of $x$. It also can be written as
\begin{equation*}
    z'+(1-n)Pz=(1 - n)Q
\end{equation*}
where
\begin{align*}
    z = y^{1-n}
\end{align*}
This is now a first-order linear equation which we can solve as we did the linear equations above. 

\subsubsection*{Exact Equations.}  $P (x, y) dx+Q(x, y)dy$ is an exact differential [the differential of $F (x, y)$, or $P dx + Q dy = dF$] if
\begin{equation*}
    \pardf P=\pardf Q
\end{equation*}
and the solution is
\begin{equation*}
    F (x, y) = \text{constant}    
\end{equation*}
An equation which is not exact may often be made exact by multiplying it by
an appropriate factor.

\subsubsection*{Homogeneous Equations.} A homogeneous function of $x$ and $y$ of degree $n$ means a function which can be written as $x^nf (y/x)$. An equation in the form
\begin{equation*}
    P (x, y) dx + Q(x, y) dy = 0
\end{equation*}
where $P$ and $Q$ are homogeneous functions of the same degree is called homogeneous. Thus,
\begin{equation*}
    y'=\df y=-\frac{P (x, y)}{Q(x, y)}-f(\frac{y}{x})
\end{equation*}
This suggests that we solve homogeneous equations by
making the change of variables
\begin{align*}
    y=xv\quad\text{with}\quad v=\frac{y}{x}
\end{align*}

\subsection*{Second Order}
\subsubsection*{Second Order with Zero Right-Hand Side.} 
Equation of the form
\begin{equation*}
    (D-a)(D-b)y=0,\quad a \neq b
\end{equation*}
has the Solution
\begin{align*}
    y = c_1e^{ax} + c_2e^{bx}
\end{align*}

Equation of the form
\begin{equation*}
    (D-a)(D-a)y=0,\quad a \neq b
\end{equation*}
has the Solution
\begin{align*}
    y = (Ax + B)e^{ax}
\end{align*}

Now suppose the roots of the auxiliary equation are $\alpha \pm i\beta $.
The solution is now
\begin{align*}
    y&=Ae^{(\alpha + i\beta)}x + Be^{(\alpha - i\beta)}x \\
    &=e^{\alpha x}(Ae^{i\beta x} + Be^{-i\beta x})\\
    &= e^{\alpha x}(c_1 \sin \beta x + c_2 \cos \beta x)\\
    &= ce^{\alpha x} \sin(\beta x + \gamma)
\end{align*}
where $\alpha,\;\beta,\;\gamma,\;c,\;c_1,\;c_2$ are different constant.

\subsubsection*{Second Order with Nonzero Right-hand Side.} The equation
\begin{align*}
    a_2\seconddf y+a_1\df y+a_0y=f(x)\\
    \seconddf y+a_1\df y+a_0y=F(x)
\end{align*}
has the solution of the form
\begin{equation*}
    y = y_c + y_p
\end{equation*}
where the complementary function $y_c$ is the general solution of the homogeneous
equation (when right-hand side is equal to zero) and $y_p$ is a particular solution, that is when the right-hand side is equal to $f(x)$ or $F(x)$.  The simplest method solving them is by Inspection and Successive Integration of Two First-Order Equations.

\subsubsection*{Exponential Right-Hand Side.} 
Suppose we have $F (x) = ke^{cx}$, or
\begin{equation*}
    (D - a)(D - b)y =ke^{cx}
\end{equation*}
then, we find a particular solution by
assuming a solution of the form:
\begin{align*}
    y_p=
    \begin{cases}
        Ce^{cx} \quad&\text{if c is not equal to either a or b;}\\
        Cxe^{cx} \quad&\text{if c equals a or b, a  $\neq$ b;}\\
        Cx^2e^{cx} \quad&\text{if c = a = b.}
    \end{cases}
\end{align*}

\subsubsection*{Complex Exponential.} To find a particular solution of
\begin{equation*}
    (D - a)(D - b)y=\begin{cases}
        k\sin \alpha x,\\
        k\cos \alpha x,
    \end{cases}
\end{equation*}
first solve
\begin{equation*}
    (D - a)(D - b)y=ke^{i\alpha x}
\end{equation*}
then take the real or imaginary part. 

\subsubsection*{Method of Undetermined Coefficients.} To find a particular solution of
\begin{equation*}
    (D - a)(D - b)y=e^{cx}P_n(x)
\end{equation*}
where $P_n(x)$ is a polynomial of degree n is
\begin{align*}
    y_p=
    \begin{cases}
        e^{cx}Q_n(x) \quad&\text{if c is not equal to either a or b;}\\
        xe^{cx}Q_n(x) \quad&\text{if c equals a or b, a  $\neq$ b;}\\
        x^2e^{cx}Q_n(x) \quad&\text{if c = a = b.}
    \end{cases}
\end{align*}
where $Q_n(x)$ is a polynomial of the same degree as $P_n(x)$ with undetermined
coefficients to be found to satisfy the given differential equation.

\subsubsection*{Principle of Superposition.} The easiest way of handling a complicated right-hand side: Solve a separate equation for each different exponential and add the solutions. The fact that this is correct for a linear equation is often called the principle of superposition. 

Note that the principle holds only for linear equations.

\subsubsection*{Fourier Series.}
Suppose that the driving force $f(x)$ is periodic, we then can expand the function using Fourier Series. The equation
\begin{equation*}
    a_2\seconddf y+a_1\df y+a_0y=f(x)=\sum_{-\infty}^{\infty}c_ne_{inx}
\end{equation*}
can be solved by solving
\begin{equation*}
    a_2\seconddf y+a_1\df y+a_0y=c_ne_{inx}
\end{equation*}
then add the solutions for all $n$ (applying principle of superposition), and we have the solution of first the equation.

\subsection*{Laplace Transform}
We define $\mathcal{L}(f )$, the Laplace transform of $f (t)$ [also written $F (p)$ since it is a function of $p$], by the equation
\begin{equation*}
    \mathcal{L}(f)=F(P)=\int_{0}^{\infty}f(t)e^{-pt};dt
\end{equation*}

\subsubsection*{Laplace transform 101.} How 2 Laplace transform in 5 steps!
\begin{enumerate}
    \item Transform!
    \item Do algebra!
    \item Inverse!
    \item $\dots$
    \item Profit!
\end{enumerate}

\subsection*{Convolution}
\subsubsection*{Definition.} The integral
\begin{equation*}
    g*h=\int_{0}^{t}g(t-\tau)h(\tau)d(\tau)=\int_{0}^{t}g(\tau)h(t-\tau)d(\tau)
\end{equation*}
is called the convolution of g and h (or the resultant or the Faltung). Now suppose that we have
\begin{equation*}
    Ay' + By' + Cy = f (t), \quad y0 = y'0 = 0
\end{equation*}
take the Laplace transform of each term, substitute the initial conditions, and solve for Y
\begin{equation*}
    Y=\frac{F(p)}{A(p + a)(p + b)}=T(p)F(p)
\end{equation*}
Then $y$ the inverse transform of $Y$ in is the inverse transform of a product of two functions whose inverse transforms we know. Let $G(p)$ and $H(p)$ be the transforms of $g(t)$ and $h(t)$
\begin{equation*}
    G(p)H(p)=\mathcal{L}(g(t)\cdot h(t))=\mathcal{L}(g*h)
\end{equation*} 
Thus
\begin{equation*}
    y=\int_{0}^{t}g(t-\tau)h(\tau)d(\tau)
\end{equation*}
Observe from $\mathcal{L}34$ that we may use either $g(t - \tau )h(\tau )$ or $g(\tau )h(t - \tau )$ in the integral. It is well to choose whichever form is easier to integrate; it is best to put$ (t - \tau )$ in the simpler function.

\subsubsection*{Fourier Transform of a Convolution.} Let $g_1(\alpha)$ and $g_2(\alpha)$ be the Fourier transforms of $f_1(x)$ and $f_2(x)$
\begin{align*}
    g_1(\alpha)\cdot g_2(\alpha)&=\frac{1}{2\pi}\int_{-\infty}^{\infty}f_1(v)e^{-i\alpha v}dv\cdot \frac{1}{2\pi}\int_{-\infty}^{\infty}f_1(u)e^{-i\alpha u}du\\
    &=\biggl(\frac{1}{2\pi}\biggr)^2\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f_1(v)f_2(u)e^{-i\alpha (v+u)}dvdu
\end{align*}
Next we make the change of variables $x = v + u$, $dx = dv$, in the v integral
\begin{align*}
    g_1(\alpha)\cdot g_2(\alpha)&= \biggl(\frac{1}{2\pi}\biggr)^2\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f_1(x-u)f_2(u)e^{-i\alpha x}dvdu\\
    &= \biggl(\frac{1}{2\pi}\biggr)^2\int_{-\infty}^{\infty}e^{-i\alpha x}\biggl[\int_{-\infty}^{\infty}f_1(x-u)f_2(u)\;du\biggr]dx
\end{align*}
if we define the term in the square parenthesis as convolution, we get 
\begin{align*}
    g_1(\alpha)\cdot g_2(\alpha)&=\frac{1}{2\pi}\biggl(\int_{-\infty}^{\infty}f_1*f_2e^{-i\alpha x}dx\biggr)\\
    &=\frac{1}{2\pi}\cdot\text{Fourier transform of }f_1*f_2
\end{align*}
In other words
\begin{equation*}
    g_1\cdot g_2\text{ and }f_1*f_2\text{ are a pair of Fourier transforms}
\end{equation*}
and by symmetry 
\begin{equation*}
    g_1* g_2\text{ and }f_1\cdot f_2\text{ are a pair of Fourier transforms}
\end{equation*}

\subsection*{Frobenius Method}
By using this method, we assume that the solution has the form of power series
\begin{equation*}
    y=\sum_{n=0}^{\infty} a_nx^{n+s}
\end{equation*}
We also assume that the first coefficient, that is $a_0$, is not zero. Computing the derivative of $y$, we obtain
\begin{align*}
    y&=\sum_{n=0}^{\infty} a_nx^{n+s} \\
    y'&=\sum_{n=0}^{\infty} (n+s) a_nx^{n+s-1}\\
    y''&=\sum_{n=0}^{\infty} (n+s) (n+s-1)a_nx^{n+s-2} 
\end{align*}

\subsubsection*{Frobenius 101.} How 2 solve differential equation using generalized power series in 5 steps!
\begin{enumerate}
    \item Tabulate!
    \item Find the column in terms of $x^{n+s}$ $x^s\rightarrow$!
    \item Factor the coefficients that contain $a_0\rightarrow$ and solve the indicial equation!
    \item Solve it in terms of $a_n=-a_{n-2}$! (not factorial!)
    \item As a check, put $n=2$ at $a_n$ not $n=0$! (also not factorial!)
\end{enumerate}

\subsection*{Bessel Function}
The first kind of Bessel function is written as 
\begin{align*}
    J_p(x)&=\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n+p}}{\Gamma(n+1)\Gamma(n+p+1)}\\
    J_{-p} (x)&=\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n-p}}{\Gamma(n+1)\Gamma(n-p+1)}
\end{align*}
While the second kind is 
\begin{equation*}
    N_p(x)=\frac{\cos(\pi p)J_p(x)-J_{-p}(x)}{\sin(\pi p)}
\end{equation*}

The Bessel function is used to solve the Bessel's equation of order $p$
\begin{equation*}
    x^2 y'' + xy' + (x^2- p^2 )y = 0
\end{equation*}
with the solution written as 
\begin{equation*}
    y=AJ_p(x)+BN_p(x)
\end{equation*}
Another form of Bessel's equation is 
\begin{equation*}
    x(xy')' + (K^2x^2- p^2 )y = 0
\end{equation*}
and the solution is 
\begin{equation*}
    y=AJ_p(Kx)+BN_p(Kx)
\end{equation*}
Another equation that can be solved by Bessel function
\begin{equation*}
    y''+ \frac{1-2a}{x}y'+ \left[(bcx^{c-1})^2+ \frac{a^2-p^2c^2}{x^2}\right]
\end{equation*}
The solution is 
\begin{equation*}
    y=x^a Z_p(bx^c)
\end{equation*}
where $a,\;b,\;c,\;p$ are constant and $Z$ denote $J$ or $N$ or any linear combination of them.

The generating function, expression that encodes an infinite sequence, for Bessel function is 
\begin{equation*}
    \exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right] =\sum_{p=-\infty}^{\infty}J_n(x)t^p
\end{equation*}

\subsubsection*{Series representation derivation.} First we write the Bessel's equation as 
\begin{equation*}
    x(xy')'+ (x^2-p^2)y=0
\end{equation*}
By the Frobenius' method
\begin{align*}
    y&=\sum_{n=0}^{\infty} a_nx^{n+s}\\
    xy'&=\sum_{n=0}^{\infty} a_n(n+s) x^{n+s}\\
    (xy')'&=\sum_{n=0}^{\infty} a_n(n+s)^2 x^{n+s-1}
\end{align*}
and 
\begin{align*}
    x(xy')'&=\sum_{n=0}^{\infty} a_n(n+s)^2 x^{n+s}\\
    x^2y&=\sum_{n=0}^{\infty} a_n x^{n+s+2}\\
    -p^2y&=-\sum_{n=0}^{\infty} a_np^2x^{n+s}
\end{align*}
Tabulate them

\begin{table}[h]
    \centering
    \caption{Table}
    \begin{tabular}{cccc } 
        \toprule
        &$x^{n+s}$&$x^s$&$x^{s+1}$\\
        \midrule
        $x(xy')'$ & $a_n(n+s)^2 $ & $a_0s^2$ &$a_1(s+1)^2$\\
        $x^2y $&$a_{n-2}$&$- $&$-$\\
        $-p^2y$ &$-a_np^2$&$-a_0p^2$&$-a_1p^2$\\
        \bottomrule
    \end{tabular}
\end{table}

From this we have the indicial equation
\begin{equation*}
    s^2-p^2=0\implies s=\pm p
\end{equation*}

And the general formula of the coefficient
\begin{equation*}
    a_n=-\frac{a_{n-2}}{(n+s)^2-p^2}
\end{equation*}
For $s=\pm p$ and odd $n$, the coefficient is zero; proved by 
\begin{equation*}
    a_1\left[(s+1)^2-p^2\right]=a_1\left[2p+1\right]=0\implies a_1=0 
\end{equation*} 

We begin first for the case $s=p$. The coefficient is given by 
\begin{equation*}
    a_n=-\frac{a_{n-2}}{(n+p)^2-p^2}=-\frac{a_{n-2}}{n^2-2np}=-\frac{a_{n-2}}{n(n+2p)}
\end{equation*}
For even $n$, we write
\begin{equation*}
    a_{2n}=-\frac{a_{2n-2}}{2n(2n+2p)}= -\frac{a_{2n-2}}{2^2n(n+p)}
\end{equation*}
The coefficients for few odd $n$ are as follows.
\begin{align*}
    a_2&=-\frac{a_0}{2^2(p+1)}=-\frac{a_0\Gamma(p+1)}{2^2\Gamma(p+2)}\\
    a_4&=-\frac{a_2}{2^22(p+2)}=-\frac{a_2\Gamma(p+2)}{2^22\Gamma(p+3)}=\frac{a_0\Gamma(p+1)}{2^42!\Gamma(p+3)}\\
    a_6&=-\frac{a_4}{2^23(p+3)}=-\frac{a_4\Gamma(p+3)}{2^23\Gamma(p+4)}=-\frac{a_0\Gamma(p+1)}{2^63!\Gamma(p+4)}
\end{align*}

The solution is written
\begin{align*}    
    y=&\;\sum_{n=0}^{\infty} a_nx^{n+p}=a_0x^p+a_2x^{p+2}+a_4 x^{p+4}+a_6x^{p+6}\\
    =&\;a_0x^p\Gamma(p+1)\bigg[\frac{1}{\Gamma(p+1)}- \frac{(x/2)^2}{\Gamma(p+2)}+\frac{(x/2)^4}{2!\Gamma(p+3)}\\
    &\quad- \frac{(x/2)^6}{3!\Gamma(p+4)}+\dots\bigg]\\
    =&\;a_02^p\Gamma(p+1)\left(\frac{x}{2}\right)^p\bigg[\frac{1}{\Gamma(1)\Gamma(p+1)}- \frac{(x/2)^2}{\Gamma(2)\Gamma(p+2)}+\frac{(x/2)^4}{\Gamma(3)\Gamma(p+3)}\\
    &\quad- \frac{(x/2)^6}{\Gamma(4)\Gamma(p+4)}+\dots\bigg]
\end{align*}
If we define 
\begin{equation*}
    a_0=\frac{1}{2p\Gamma(p+1)}
\end{equation*}
then the solution, which is defined as $J_p(x)$, is written
\begin{multline*}
    J_p(x)=\frac{(x/2)}{\Gamma(1)\Gamma(p+2)}-\frac{(x/2)^{p+2}}{\Gamma(3)\Gamma(p+3)} +\frac{(x/2)^{p+4}}{\Gamma(3)\Gamma(p+3)} \\
    -\frac{(x/2)^{p+6}}{\Gamma(4)\Gamma(p+4)} +\dots
\end{multline*}
or
\begin{equation*}
    J_p(x)=\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n+p}}{\Gamma(n+1)\Gamma(n+p+1)}
\end{equation*}

Next we consider the solution for $s=-p$. Since the steps are the same, we only need to change the sign of $p$. The solution is written
\begin{equation*}
    J_{-p} (x)=\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n-p}}{\Gamma(n+1)\Gamma(n-p+1)}
\end{equation*}

As an aside, for the Bessel equation written in the form 
\begin{equation*}
    x^2y'' +xy' + (K^2x^2- p^2 )y = 0
\end{equation*}
All the terms are unchanged except the term 
\begin{equation*}
    K^2x^2y=\sum_{n=0}^{\infty} a_n K^2x^{n+s+2}
\end{equation*}
This will result the change of argument in the Bessel equation from $Z(x)$ into $Z(Kx)$.

\subsubsection*{Generating function proof.} Proved by writing it out.
\begin{align*}
    \exp\left[\frac{xt}{2}\right] \exp\bigg[-\frac{x}{2t}\bigg]&=\sum_{n=0}^{\infty}\frac{(xt/2)^n}{n!}\sum_{m=0}^{\infty} \frac{(-x/2t)^m}{m!}\\
    \exp\left[\frac{xt}{2}\right] \exp\bigg[-\frac{x}{2t}\bigg]&=\sum_{n=0}^{\infty}\sum_{m=0}^{\infty}(-1)^m\frac{t^{n-m}}{n!m!}\left(\frac{x}{2}\right)^{n+m}
\end{align*}
We then define $p\equiv n-m$ to shift the indices
\begin{equation*}
    \exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right]= \sum_{p=-\infty}^{\infty}\sum_{m=0}^{\infty}\frac{(-1)^m(x/2)^{p+2m}}{(p+m)!m!}t^p=\sum_{p=-\infty}^{\infty}J_p(x)t^p
\end{equation*}

\subsubsection*{Recursive relation.} Here are few relations of Bessel function with its derivative.
\begin{gather*}
    J_{p-1}(x)+J_{p+1}(x)=\frac{2p}{x}J_p(x)\\
    J_{p-1}(x)- J_{p+1}(x)=2J'_p(x)\\
    \frac{d}{dx}[x^pJ_p(x)]=x^pJ_{p-1}(x)\\
    \frac{d}{dx}[x^{-p}J_p(x)]=-x^{-p}J_{p+1}(x)\\
    J'_p(x)=-\frac{p}{x}J_p(x)+J_{p-1}(x)=\frac{p}{x}J_p(x)-J_{p+1}(x)
\end{gather*}
And bonus relation that only apply for integral $p$
\begin{gather*}
    J_{-p}(x)=(-1)^pJ_p(x)\\
    J_p(-x)=(-1)^pJ_p(x)
\end{gather*}


\paragraph*{First relation proof.} Differentiate the expression for generating function with respect to $t$
\begin{align*}
    \frac{x}{2}\left(1+\frac{1}{t^2}\right)\exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right]&=\sum_{p=-\infty}^{\infty}pJ_p(x)t^{p-1}\\
    \sum_{p=-\infty}^{\infty}\left[J_p(x)+J_{p-2}(x)\right]t^p&= \sum_{p=-\infty}^{\infty}\frac{2p}{x}J_{p+1}t^{p}
\end{align*}
Taking the constant for the term $t^p$, we have 
\begin{equation*}
    J_p(x)+J_{p-2}(x)=\frac{2p}{x}J_{p+1} 
\end{equation*}

\paragraph*{Second relation proof.} Differentiate with respect to $x$ instead 
\begin{align*}
    \frac{1}{2}\left(t-\frac{1}{t}\right)\exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right]&=\sum_{p=-\infty}^{\infty}J'_p(x)t^{p}\\
    \sum_{p=-\infty}^{\infty}\left[J_{p+1}(x)+J_{p-1}(x)\right]t^p&= \sum_{p=-\infty}^{\infty}2J'_pt^{p}
\end{align*}
and as before, we have 
\begin{equation*}
    J_{p+1}(x)+J_{p-1}(x)=2J'_p
\end{equation*}

\paragraph*{Third relation proof.} Simply evaluate the derivative and use both first and second relation
\begin{align*}
    \frac{d}{dx}\left[x^pJ_p(x)\right]&= \frac{x^p}{2}\left[J_{p-1}(x)+J_{p+1}(x)\right]+\frac{x^p}{2}\left[J_{p-1}(x)-J_{p+1}(x)\right]\\
    \frac{d}{dx}\left[x^pJ_p(x)\right]&=x^pJ_{p-1}(x)
\end{align*}

\paragraph*{Fourth relation proof.} The same as the third 
\begin{align*}
    \frac{d}{dx}\left[x^{-p}J_p(x)\right]&= -\frac{x^{-p}}{2}\left[J_{p-1}(x)+J_{p+1}(x)\right]+\frac{x^p}{2}\left[J_{p-1}(x)-J_{p+1}(x)\right]\\
    \frac{d}{dx}\left[x^{-p}J_p(x)\right]&=x^{-p}J_{p+1}(x)
\end{align*}

\paragraph*{Fifth relation proof.} Add both first and second relation to obtain the middle side 
\begin{align*}
    2J_{p-1}(x)&=\frac{2p}{x}J_p(x)+2J'_p(x)\\
    J'_{p}(x)&=J_{p-1}(x)-\frac{p}{x}J_p(x)
\end{align*}
and subtract to obtain the right side
\begin{align*}
    2J_{p+1}(x)&=\frac{2p}{x}J_p(x)-2J'_p(x)\\
    J'_{p}(x)&=\frac{p}{x}J_p(x)-J_{p+1}(x)
\end{align*}

\subsubsection*{Orthogonality.} Suppose $\alpha$ and $\beta$ are the zeros of the Bessel function order $p$. We can say that the function $\sqrt{x}J_p(\alpha x)$ is orthogonal with itself on $(0,1)$. We can also say that the functions $J_p^2(\alpha x)$ are orthogonal with respect with weight function $x$. Thus, we write
\begin{equation*}
    \int_{0}^{1}xJ_p(\alpha x)J_p(\beta x)\;dx=\begin{cases}
        0&\alpha\neq \beta\\
        \dfrac{1}{2}{J'_p}^2(\alpha)=\dfrac{1}{2}J_{p+1}^2(\alpha) =\dfrac{1}{2}J_{p-1}^2(\alpha)&\alpha=\beta
    \end{cases}
\end{equation*}
We can change the integration limit by substituting $x=r/a$
\begin{equation*}
    \int_{0}^{a}rJ_p\left(\alpha \frac{r}{a}\right)J_p\left(\beta \frac{r}{a}\right)\;dr=\begin{cases}
        0\\
        \qquad \alpha\neq \beta\\
        \dfrac{a^2}{2}{J'_p}^2(\alpha)=\dfrac{a^2}{2}J_{p+1}^2(\alpha) =\dfrac{a^2}{2}J_{p-1}^2(\alpha)\\
        \qquad\alpha=\beta
    \end{cases}
\end{equation*}

\paragraph*{Proof.} To prove the relation orthogonality of the Bessel function on $(0,1)$ with respect to the weight function $x$, consider the equations 
\begin{align*}
    x(xy')'+(\alpha^2x^2-p^2)y&=0\\
    x(xy')'+(\beta^2x^2-p^2)y&=0
\end{align*}
which are solved by the functions $J_p(\alpha x)$ and $J_p(\beta x)$ respectively. For brevity's sake, we define $J_p(\alpha x)\equiv u$,  $J_p(\beta x)\equiv v$ and we write
\begin{align*}
    x(xu')'+(\alpha^2x^2-p^2)u&=0\\
    x(xv')'+(\beta^2x^2-p^2)v&=0
\end{align*}
Multiplying the first equation with $u$ and the second with $v$
\begin{align*}
    xv(xu')'+(\alpha^2x^2-p^2)uv&=0\\
    xu(xv')'+(\beta^2x^2-p^2)vu&=0
\end{align*}
Subtracting them 
\begin{align*}
    xv(xu')'-xu(xv')'+(\alpha^2-p^2)x^2uv&=0\\
    v(xu')'-u(xv')'+(\alpha^2-p^2)xuv&=0
\end{align*}
Note that we can write the first two terms as
\begin{align*}
    \frac{d}{dx}\left(vxu'-uxv'\right)&=x'xu'+v(xu)'-u'xv'-u(xv')'\\
    &=v(xu')'-u(xv')'
\end{align*}
On integrating it within $(0,1)$
\begin{equation*}
    \left(vxu'-uxv'\right)\bigg|_0^1+\int_{0}^{1}(\alpha^2-p^2)xuv\;dx=0
\end{equation*}
By the definition
\begin{equation*}
    J_p(\beta)J_p'(\alpha) -J_p(\alpha)j_p'(\beta) +\int_{0}^{1}(\alpha^2-p^2)xJ_p(\alpha)j_p(\beta)\;dx=0
\end{equation*}
where the value at lower limit of those two terms are zero. Since both $\alpha$ and $\beta$ are the zeros of the Bessel functions
\begin{equation*}
    \int_{0}^{1}(\alpha^2-p^2)xJ_p(\alpha)J_p(\beta)\;dx=0
\end{equation*}
If $\alpha\neq\beta$, the terms inside parenthesis are not equal to zero. Hence,
\begin{equation*}
    \int_{0}^{1}xJ_p(\alpha)J_p(\beta)\;dx=0
\end{equation*}
If $\alpha\neq\beta$, the terms inside parenthesis are not equal to zero. Hence, we can simply divide both side by it and the integral is not zero. To find its value, suppose that $\beta$ is not a zero, unlike $\alpha$. We can write 
\begin{equation*}
    \int_{0}^{1}xJ_p(\alpha)J_p(\beta)\;dx=\frac{\alpha J_p(\beta)J_p(\alpha)}{\beta^2-\alpha^2}
\end{equation*}
Now we let $\beta\rightarrow\alpha$ and evaluate the right term using  L'Hôpital's rule to find 
\begin{equation*}
    \lim_{\beta\rightarrow\alpha}\frac{\alpha J_p(\beta)J_p'(\alpha)}{\beta^2-\alpha^2} =\lim_{\beta\rightarrow\alpha}\frac{\alpha J_p'(\beta)J_p'(\alpha)}{2\beta}=\frac{1}{2}J_p'(\alpha)
\end{equation*}


\subsubsection*{Hankel's function.} If the first and the second kind of Bessel function are analog to sin and cos, the Hankel's function is an analog to $\exp(\pm ix)=\cos x \pm i\sin x$. The function is defined as  
\begin{align*}
    H_p^{(1)}(x)&=J_p(x)+iN_p(x)\\
    H_p^{(2)}(x)&=J_p(x)-iN_p(x)
\end{align*}

\subsubsection*{Hyperbolic Bessel functions.} This function is the solution of 
\begin{equation*}
    x^2y''+xy'-(x^2+p^2)y=0
\end{equation*}
and defined as 
\begin{align*}
    I_p&=i^{-p}J_p(ix)\\
    K_p(x)&=\frac{\pi}{2}i^{p+1}H_p^{(1)}(ix)
\end{align*}
They are analog to $\sinh x= -i\sin (ix)$ and $\cosh x=\cos (ix)$ respectively.

\subsubsection*{Spherical Bessel functions.} If $p$ is a half integer
then the Bessel function $Z_p(x)$ is defined to be spherical Bessel function and defined as follows
\begin{align*}
    j_n(x)&=\sqrt{\frac{\pi}{2x}}J_{n+1/2}(x)=\left(-\frac{d}{dx}\right)^n\left(\frac{\sin x}{x}\right)\\
    y_n(x)&=\sqrt{\frac{\pi}{2x}}Y_{n+1/2}(x)=\left(\frac{d}{dx}\right)^n\left(\frac{\cos x}{x}\right)\\
    h_n^{(1)}(x)&=j_n(x)+iy_n(x)\\
    h_n^{(2)}(x)&=j_n(x)-iy_n(x)
\end{align*}
From this we can obtain 
\begin{equation*}
    J_{1/2}(x)=\frac{2}{\pi x}\sin x, \quad J_{-1/2}(x)=\frac{2}{\pi x}\cos x
\end{equation*} 

\subsection*{Legendre Function}
The Legendre differential equation
\begin{equation*}
    (1-x^2)y''-2xy'+l(l+1)y=0
\end{equation*}
has the solution of Legendre polynomial, which by the Rodrigues formula is 
\begin{equation*}
    P_l(x)=\frac{1}{2^ll!}\frac{d^l}{dx^l}(x^2-1)^l
\end{equation*}
The Legendre polynomial is defined such that $y(1)=P_l(1)=1$.

Another closely related equation is 
\begin{equation*}
    (1-x^2)y''-2xy'+\left[l(l+1)-\frac{m^2}{1-x^2}\right]y =0
\end{equation*}
The solution of said function is the associated Legendre function, which defined by the Rodrigues formula as 
\begin{equation*}
    P_l^m(x)=\frac{1}{2^ll!}(1-x^2)^{\frac{m}{2}}\left(\frac{d}{dx}\right)^{l+m}(x^2-1)^l
\end{equation*}

\subsubsection*{Laplace integral representation.} The integral representation for the Legendre polynomial is 
\begin{equation*}
    P_l(x)=\frac{1}{\pi}\int_{0}^{\pi}\left(x+\sqrt{x^2-1}\cos\theta\right)^l\;d\theta
\end{equation*}

\subsubsection*{Series derivation.} By assuming the solution has the form of power series, we can use the Frobenius method. We also assume that $s=0$ for simplification. Thus, each term can be represented as power series
\begin{center}
    \begin{tabular}{r c l c}
        \toprule
        &&&$x^n$\\
        \midrule
        $y''$&$=$&$\displaystyle\sum_{n=0}^{\infty} n(n-1)a_nx^{n-2}$ &$(n+2)(n+1)a_{n+2}$ \\
        $-x^2y''$&$=$&$\displaystyle\sum_{n=0}^{\infty} n(n-1)a_nx^{n}$ &$-n(n-1)a_n$ \\
        $-2xy'$&$=$&$\displaystyle\sum_{n=0}^{\infty} na_nx^{n}$ & $-na_n$\\
        $l(l+1)y$&$=$&$\displaystyle\sum_{n=0}^{\infty} l(l+1)a_nx^{n}$ & $l(l+1)a_n$\\
        \bottomrule
    \end{tabular}
\end{center}
From the $x^n$ coefficient
\begin{equation*}
    (n+2)(n+1)a_{n+2}=-a_n[-n(n-1)-n+l(l+1)]
\end{equation*}
We write the coefficient of the $a_s$ as follows
\begin{multline*}
    -n(n-1)-n+l(l+1)=-n^2-2n+l^2+l=l^2-n^2+l-n\\
    =(l+n)(l-n)+l-n=(l-n)(l+n+1)
\end{multline*}
The formula for $n+2$ term is then
\begin{equation*}
    a_{n+2}=-\frac{(l-n)(l+n+1)}{(n+2)(n+1)}a_n
\end{equation*}
Here we have few terms
\begin{align*}
    a_2&=-\frac{l(l+1)}{2!}a_0\\
    a_3&=-\frac{(l-1)(l+2)}{3!}a_1\\
    a_4&=-\frac{(l-2)(l+3)}{4\cdot3}a_2=\frac{l(l+1)(l-2)(l+3)}{4!}a_0\\
    a_5&=-\frac{(l-3)(l+4)}{5\cdot4}a_3=\frac{(l-1)(l+2)(l-3)(l+4)}{5!}a_1
\end{align*}
Since neither $a_0$ and $a_1$ not zero, the solution is a superposition of two series in terms of $a_0$ and $a_1$
\begin{multline*}
    y=a_0\left[1-\frac{l(l+1)}{2!}x^2+\frac{l(l+1)(l-2)(l+3)}{4!}x^4-\dots\right]\\
    +a_1\left[x-\frac{(l-1)(l+2)}{3!}x^3+\frac{(l-1)(l+2)(l-3)(l+4)}{5!}x^5-\dots\right]
\end{multline*}

Now consider $l=0$. The solution takes the form 
\begin{equation*}
    y=a_0+a_1\left[x-\frac{1}{3}x^3+\frac{1}{5}x^5-\dots\right]
\end{equation*}
At $x^2=1$ the $a_1$ series is divergent by the integral test
\begin{equation*}
    \int^\infty \frac{1}{2n+1}\;dn=\frac{1}{2}\ln (2n+1)\bigg|^{\infty}=\infty
\end{equation*}
Therefore we throw the $a_1$ series out. By the definition of Legendre polynomial we have $a_0=1$, thus $P_0(x)=1$. We can use this method to determine the value of $P_l(x)$ for other $l$, but this method is simply terrible to use. There are other method that are more efficient, Rodrigues formula for example.

\subsubsection*{Rodrigues formula proof.} Consider the function $v=(x^2-1)^l$. Differentiate it with respect to $x$
\begin{equation*}
    \frac{dv}{dx}=l(x^2-1)^{l-1}2x
\end{equation*}
Multiply it with $(x^2-1)$
\begin{equation*}
    (x^2-1)\frac{dv}{dx}=2lxv
\end{equation*}
Differentiate $l+1$ times, which according to the Leibniz’ rule for differentiation
\begin{align*}
    \frac{d^{l+1}}{dx^{l+1}}fg&=\sum_{k=0}^{l+1}\frac{(l+1)!}{k!(l+1-k)!}\left(\frac{d}{dx}\right)^{l+1-k}f\left(\frac{d}{dx}\right)^{k}g\\
    &=\left(\frac{d}{dx}\right)^{l+1}f\left(\frac{d}{dx}\right)^{0}g+ (l+1)\left(\frac{d}{dx}\right)^{l}f\left(\frac{d}{dx}\right)^{1}g \\
    &\qquad+\frac{l(l+1)}{2}\left(\frac{d}{dx}\right)^{l-1}f\left(\frac{d}{dx}\right)^{2}g+\dots
\end{align*}
For the left side, we take $f=dv/dx$ and $g=(x^2-1)$
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}\left[\frac{dv}{dx}(x^2-1)\right]= (x^2-1)\frac{d^{l+2}v}{dx^{l+2}}+2(l+1)x\frac{d^{l+1}v}{dx^{l+1}}+\frac{2l(l+1)}{2!}\frac{d^{l}v}{dx^{l}}
\end{equation*}
As for the right side, we take $f=v$ and $g=x$
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}\left[2lvx\right]=2lx\frac{d^{l+1}v}{dx^{l+1}} +2l(l+1)\frac{d^{l}v}{dx^{l}}
\end{equation*}
Equating both side 
\begin{align*}
    (1-x^2)\frac{d^{l+2}v}{dx^{l+2}} +\left[2xl-2x(l+1)\right]\frac{d^{l+1}v}{dx^{l+1}} +\left[2l(l+1)-l(l+1)\right]\frac{d^{l}v}{dx^{l}}&=0\\
    (1-x^2)\left(\frac{d^lv}{dx^l}\right)' -2x\left(\frac{d^lv}{dx^l}\right)' +l(l+1)\frac{dv}{dx}&=0
\end{align*}
This is the Legendre's equation if
\begin{equation*}
    y=\frac{d^lv}{dx^l}=\frac{d^l}{dx^l} (x^2-1)^l
\end{equation*}

The next step is to apply the definition of Legendre polynomial $P_l(1)=1$. This can be achieved by determining the value of constant $C$ such that 
\begin{equation*}
    y(1)=C\frac{d^l}{dx^l} (x^2-1)^l\bigg|_{x=1}=1
\end{equation*}
We use the relation 
\begin{equation*}
    \frac{d^l}{dx^l}(x^2-1)^l\bigg|_{x=1}=2^ll!
\end{equation*}
which can be proofed by the induction method. First, consider the base case of $l=0$. According to the hypothesis,
\begin{align*}
    \frac{d^0}{dx^0}(x^2-1)^0\bigg|_{x=1}&=2^00!\\
    1&=1
\end{align*}
Then consider the inductive case $l+1$
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1}\bigg|_{x=1}=2^{l+1}(l+1)!
\end{equation*}
By the Leibniz' rule, we set $f=(x^2-1)^l$ and $g=(x^2-1)$
\begin{multline*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1} =(x^2-1)\frac{d^{l+1}}{dx^{l+1}}(x^2-1)^l +2(l+1)x\frac{d^{l}}{dx^{l}}(x^2-1)^l \\
    +\frac{2l(l+1)}{2!}\frac{d^{l-1}}{dx^{l-1}}(x^2-1)^l
\end{multline*}
On evaluating it at $x=1$, we have the first and the third term to be zero. The first one is obvious enough; but for the third term, note that the term $(x^2-1)$ will survive, thus evaluating at $x=1$ will result in said term to be zero also. All that remain is the second term
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1}\bigg|_{x=1}=2(l+1)x\frac{d^{l}}{dx^{l}}(x^2-1)^l
\end{equation*}
By using the hypothesis, we have completed our proof
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1}\bigg|_{x=1}=2(l+1)x2^ll!=2^{l+1}(l+1)!
\end{equation*}
Since the relation have been proofed, we can use it to obtain 
\begin{equation*}
    C\frac{d^l}{dx^l} (x^2-1)^l\bigg|_{x=1}=1\implies C=\frac{1}{2^ll!}
\end{equation*}
Thus 
\begin{equation*}
    y(x)=P_l(x)=\frac{1}{2^ll!}\frac{d^l}{dx^l} (x^2-1)^l
\end{equation*}

We begin the proof of the Rodrigues formula for associated Legendre polynomial by substituting
\begin{equation*}
    y=(1-x^2)^{\frac{m}{2}}u
\end{equation*}
Now we evaluate the first derivative
\begin{align*}
    y'&=u\frac{m}{2}(1-x^2)^{\frac{m}{2}-1}(-2x)+ (1-x^2)^{\frac{m}{2}}u'\\
    y'&=(1-x^2)^{\frac{m}{2}}u'-mx(1-x^2)^{\frac{m}{2}-1}u 
\end{align*}
Then the second
\begin{align*}
    y''&=(1-x^2)^{\frac{m}{2}}u''-mx(1-x^2)^{\frac{m}{2}-1}u' -mx(1-x^2)^{\frac{m}{2}-1}u'\\
    &\quad-mu\left[(1-x^2)^{\frac{m}{2}-1} +x\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-2}(-2x)\right] \\
    y''&=(1-x^2)^{\frac{m}{2}}u''-2mx(1-x^2)^{\frac{m}{2}-1}u' \\
    &\quad-m\left[(1-x^2)^{\frac{m}{2}-1} -2x^2\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-2}\right]u
\end{align*}
Now consider the equation that we are going to solve 
\begin{equation*}
    (1-x^2)y''-2xy'+\left[l(l+1)-\frac{m^2}{1-x^2}\right]y =0
\end{equation*}
On using the substituted value of $y$ and its derivatives, we can write the first term as 
\begin{align*}
    (1-x^2)y''&=(1-x^2)^{\frac{m}{2}+1}u''-2mx(1-x^2)^{\frac{m}{2}}u' \\
    &\quad-m\left[(1-x^2)^{\frac{m}{2}} -2x^2\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-1}\right]u
\end{align*}
then the second 
\begin{equation*}
    -2xy'=2mx^2(1-x^2)^{\frac{m}{2}-1}u -2x(1-x^2)^{\frac{m}{2}}u'
\end{equation*}
and the third
\begin{equation*}
    \left[l(l+1)-\frac{m^2}{1-x^2}\right]y=\left[l(l+1)(1-x^2)^{\frac{m}{2}}-m^2(1-x^2)^{\frac{m}{2}-1}\right]u
\end{equation*}
Hence we have 
\begin{gather*}
    (1-x^2)^{\frac{m}{2}+1}u''-2(m+1)x(1-x^2)^{\frac{m}{2}}u' \\
    +\bigg[l(l+1)(1-x^2)^{\frac{m}{2}}-m^2(1-x^2)^{\frac{m}{2}-1}\\
    +2mx^2(1-x^2)^{\frac{m}{2}-1} \\
    -m(1-x^2)^{\frac{m}{2}} +2mx^2\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-1}\bigg]u=0      
\end{gather*}
Terms inside square bracket can be simplified into 
\begin{equation*}
    l(l+1)(1-x^2)^{\frac{m}{2}}-m^2(1-x^2)^{\frac{m}{2}-1} -m(1-x^2)^{\frac{m}{2}} +m^2x^2(1-x^2)^{\frac{m}{2}-1}
\end{equation*}
Then 
\begin{equation*}
    l(l+1)(1-x^2)^{\frac{m}{2}}-m(1-x^2)^{\frac{m}{2}} -m^2(1-x^2)(1-x^2)^{\frac{m}{2}-1}
\end{equation*}
Finally 
\begin{equation*}
    l(l+1)(1-x^2)^{\frac{m}{2}} -m(m+1)(1-x^2)^{\frac{m}{2}}
\end{equation*}
Substituting back and multiplying by $(1-x^2)^2/m$
\begin{equation*}
    (1-x^2)u''-2(m+1)xu'+\left[l(l+1)-m(m+1)\right]u=0
\end{equation*}
Now the associated Legendre equation turns into the Legendre equation if $m=0$ and has solution of $u=P_l$ or $(1-x^2)^{\frac{m}{2}}P_l$,  the solution is. For the case of general integer $m$, first differentiate it, to obtain
\begin{gather*}
    -2xu'' +(1-x^2)u'''-2(m+1)(u'+xu'')\\
    +\left[l(l+1)-m(m+1)\right]u'=0
\end{gather*}
Or 
\begin{gather*}
    (1-x^2)(u')''-[2(m+1)+2]x(u')'\\
    +\left[l(l+1)-m(m+1)-2(m+1)\right]u'=0
\end{gather*}
This just the previous Legendre equation with $u\rightarrow u'$ and $m\rightarrow m+1$. If $u=P_l$ is the solution at $m=0$ and $u=P_l'$ is the solution at $m+1$, then by the induction method we can say that for interger $0\leq m\leq l$, $u=(P_l)^{(m)}$ is the solution. To put in anothe words, the solution of associated Legendre equation is 
\begin{align*}
    y&=(1-x^2)^{\frac{m}{2}}\left(\frac{d}{dx}\right)P_l\\
    y&=\frac{1}{2^ll!}(1-x^2)^{\frac{m}{2}}\left(\frac{d}{dx}\right)^{l+m}(x^2-1)^l
\end{align*}


\subsubsection*{Generating function.} The function $\Phi(x,h)$ below is the generating function for the Legendre polynomial
\begin{equation*}
    (1-2x+h^2)^{-1/2}=\sum_{l=0}^{\infty}h^lP_l(x)
\end{equation*}

\paragraph*{Proof.} We first show that  the function indeed can be expressed as series. For brevity, we take $u=2xh-h^2$
\begin{align*}
    (1-u)^{-1/2} &=\sum_{k=0}^{\infty}\frac{\Gamma(1/2)(-u)^k}{\Gamma(k+1)\Gamma(1/2-k)}\\
    &=1+\frac{1}{2}u+\frac{(-1/2)(-3/2)}{\Gamma(3)}u^{2}+\dots\\
    &=1+\frac{1}{2}(2xh-h^2)+\frac{3}{8}(4x^2-4xh^3+h^2)+\dots\\
    &=1+ xh +\left(\frac{3}{2}x^2-\frac{1}{2}\right)h^2+\dots\\
    \Phi(x,h)&=P_0(x) +hP_1(x) +h^2P_2(x) +\dots
\end{align*}
By evaluating the series at $x=1$, we have the expression in terms of $h$
\begin{equation*}
    \Phi(1,h)=P_0(1) +hP_1(1) +h^2P_2(1) +\dots
\end{equation*}
thus, the function does indeed have the identity $P_l(1)=1$. Next we will show that the generating function satisfies the Legendre equation by the following formula
\begin{equation*}
    (1-x^2)\frac{\partial^2\Phi}{\partial x^2}-2x\frac{\partial\Phi}{\partial x}+h\frac{\partial^2h\Phi}{\partial h^2}=0
\end{equation*} 
Substituting the series representation of the generating function 
\begin{equation*}
    (1-x^2)\sum_{l=0}^{\infty}h^lP''_l(x) -2x\sum_{l=0}^{\infty}h^lP'_l(x) +\sum_{l=0}^{\infty}(l+1)lh^lP_l(x)=0
\end{equation*} 
Taking the coefficient of $h^l$, we obtain the Legendre function
\begin{equation*}
    (1-x^2)P''_l(x) -2xP'_l(x) +l(l+1)P_l(x)=0
\end{equation*} 

\subsubsection*{Recursion relations.} Some examples of recursion
relations areas follows.
\begin{gather*}
    lP_l(x)=(2l-l)xP_{l-1}(x)-l(-1)P_{l-2}(x)\\
    xP_l'-P_{l-1}'=lP_l(x)\\
    P_l'(x)xP_{l-1}'=lP_{l-1}(x)\\
    (1-x^2)P_l'(x)=lP_{l-1}(x)lxP_l(x)\\
    (2l+1)P_l(x)=P_{l+1}'(x)-P_{l-1}'{x}\\
    (1-x^2)P_{l-1}'(x=lxP_{l-1})(x)-lP_{l}(x)
\end{gather*}
Also some identity
\begin{equation*}
    P_l(-x)=(-1)^lP_l(x)
\end{equation*}

\paragraph*{First relation proof.} Differentiate the generating function with respect to $h$
\begin{equation*}
    \frac{\partial \Phi}{\partial h}=-\frac{1}{2}(1-2xh+h^2)^{-3/2}(-2x+2h)
\end{equation*}
Or 
\begin{equation*}
    (1-2xh+h^2)\frac{\partial \Phi}{\partial h}=(x-h)\Phi
\end{equation*}
First write it as power series
\begin{equation*}
    (1-2xh+h^2)\sum_{l=0}^{\infty}lh^{l-1}P_l(x)=(x-h)\sum_{l=0}^{\infty}h^lP_l
\end{equation*}
then take the $h^{l-1}$ coefficient
\begin{equation*}
    lP_l-2x(l-1)P_{l-1}+(l-2)P_{l-2}=xP_{l-1}-P_{l-2}
\end{equation*}
Rearrange it 
\begin{align*}
    lP_l&=\left[2x(l-1)+x\right]P_{l-1} -\left[l-2+1\right]P_{l-2}\\
    lP_l&=(2l-l)xP_{l-1}(x)-l(-1)P_{l-2}(x)
\end{align*}

\paragraph*{Second relation proof.} 404. 

\paragraph*{Third relation proof.} 404.

\paragraph*{Fourth relation proof.} 404.

\paragraph*{Fifth relation proof.} 404.

\paragraph*{Sixth relation proof.} 404.

\subsubsection*{Orthogonality.} The following equation state the orthogonality of Legendre polynomial on $(-1,1)$
\begin{equation*}
    \int_{-1}^{1}P_l(x)P_m(x)\;dx=\frac{2}{2l+1}\delta_{lm}
\end{equation*}
On using this, we also obtain the following theorem.
\begin{equation*}
    \int_{-1}^{1}P_l(x)\cdot(\text{polynomial degree }l<0)\;dx=0
\end{equation*}

For the case of associated Legendre polynomial, we have 
\begin{equation*}
    \int_{-1}^{1}[P_l^m(x)]^2\;dx=\frac{2}{2l+1}\frac{(l+m)!}{(l-m)!}
\end{equation*}

\paragraph*{Proof.} Consider two Legendre polynomials for two different value of $l$ 
\begin{align*}
    \frac{d}{dx}\left[(1-x^2)P_l'\right] +l(l+1) P_l&=0\\
    \frac{d}{dx}\left[(1-x^2)P_m'\right] +l(l+1) P_m&=0
\end{align*}
Multiply the first equation with $P_m$ and the second with $P_l$
\begin{align*}
    P_m\frac{d}{dx}\left[(1-x^2)P_l'\right] +l(l+1) P_lP_m&=0\\
    P_l\frac{d}{dx}\left[(1-x^2)P_m'\right] +m(m+1) P_lP_m&=0
\end{align*}
Subtract both 
\begin{multline*}
    P_m\frac{d}{dx}\left[(1-x^2)P_l'\right]
    -P_l\frac{d}{dx}\left[(1-x^2)P_m'\right]\\
    +\left[(l(l+1))-m(m+1)\right]P_lP_m
\end{multline*}
The first two terms can be written as 
\begin{align*}
    \frac{d}{dx}\left[(1-x^2)(P_mP_l'-P_lP_m')\right]&= \frac{d}{dx}\left[(1-x^2)P_mP_l'-(1-x^2P_lP_m')\right]\\
    &=(1-x^2)P_l'P_m' +P_m\frac{d}{dx}\left[(1-x^2)P_l'\right]\\
    &\qquad-(1-x^2)P_l'P_m' -P_l\frac{d}{dx}\left[(1-x^2)P_m'\right]
\end{align*}
which is what those two terms are. Then integrate between $(-1,1)$
\begin{multline*}
    \int_{-1}^{1}\frac{d}{dx}\left[(1-x^2)(P_mP_l'-P_lP_m')\right]\;dx \\
    +\int_{-1}^{1} \left[(l(l+1))-m(m+1)\right]P_lP_m\;dx=0
\end{multline*}
Evaluate it
\begin{equation*}
    (1-x^2)(P_mP_l'-P_lP_m')\bigg|_{-1}^{1} +\left[(l(l+1))-m(m+1)\right]\int_{-1}^{1} P_lP_m \; dx=0
\end{equation*}
The first term is zero due to the term of $(1-x^2)$; while the second term is also zero if $m=l$, which due to the constant term outside integral. Hence, it is proved that for $m=l$, the following integral is true 
\begin{equation*}
    \int_{-1}^{1} P_lP_m \; dx=0
\end{equation*}
By considering $P_m$ as a polynomial order $m$, we can also state 
\begin{equation*}
    \int_{-1}^{1} P_l\cdot(\text{polynomial degree }l<0)\; dx=0
\end{equation*}

To prove the value of the integral for the same order $l$, first recall the recursive relation of 
\begin{equation*}
    lP_l=xP_l'-P_{l-1}'
\end{equation*}
Multiply by $P_l$ and integrate on $(-1,1)$
\begin{equation*}
    l\int_{-1}^{1}[P_l]^2\;dx=\int_{-1}^{1}xP_lP_l'\;dx -\int_{-1}^{1}P_lP_{l-1}'\;dx
\end{equation*}
The second term is zero since $P_{l-1}'$ is a polynomial order $l-2$. We evaluate the remaining integral using integration by part 
\begin{equation*}
    \int_{-1}^{1}xP_lP_l'\;dx =x[P_l]^2\bigg|_{-1}^{1}-\int_{-1}^{1}P_l\frac{d}{dx}\left[xP_l\right]\;dx
\end{equation*}
Recalling the $[P_l(-1)]^2=(-1)^{2l}=1$ and using the derivative product rule for the second integral
\begin{align*}
    \int_{-1}^{1}xP_lP_l'\;dx &=2-\int_{-1}^{1}[P_l]^2\;dx -\int_{-1}^{1}xP_lP_l'\;dx\\
    \int_{-1}^{1}xP_lP_l'\;dx&=1-\frac{1}{2}\int_{-1}^{1}[P_l]^2\;dx
\end{align*}
Then substituting back into our original equation
\begin{align*}
    l\int_{-1}^{1}[P_l]^2\;dx=1-\frac{1}{2}\int_{-1}^{1}[P_l]^2\;dx\\
    \int_{-1}^{1}[P_l]^2\;dx=\frac{1}{l+1/2}=\frac{2}{2l+1}
\end{align*}
Or by using Kronecker delta, we can also express the result as 
\begin{equation*}
    \int_{-1}^{1}P_lP_m\;dx=\frac{2}{2l+1}\delta_{lm}
\end{equation*}

\subsection*{Laplace's Equation}
Consider scalar function $u$, which may represent gravitational potential in a region containing no mass, the electrostatic potential in a charge-free region, the steady-state temperature in a region containing no sources of heat, or the velocity potential for an incompressible fluid with no vortices and no sources or sinks. Laplace's equation state that 
\begin{equation*}
    \nabla^2 u=0
\end{equation*}

\subsubsection*{Cylindrical domain.} Suppose we evaluate Laplace equation in cylindrical domain. The Laplacian reads
\begin{equation*}
    \nabla^2u= \frac{1}{r}\frac{\partial}{\partial r}\Biggl(r\frac{\partial u}{\partial r}\Biggr)+\frac{1}{r^2} \frac{\partial^2u}{\partial \phi^2}+ \frac{\partial^2u}{\partial z^2}
\end{equation*}

By the separation of variables, we assume the solution of $u=R(r)\Phi(\phi)Z(z)$. Thus, the Laplace's equation now reads
\begin{equation*}
    \frac{\Phi R}{r}\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +\frac{RZ}{r^2} \frac{\partial^2\Phi}{\partial \phi^2}
    + R\Phi\frac{\partial^2Z}{\partial z^2}=0
\end{equation*}
Then we divide by $u=R(r)\Phi(\phi)Z(z)$,
\begin{equation*}
    \frac{1}{Rr}\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +\frac{1}{\Phi r^2} \frac{\partial^2\Phi}{\partial \phi^2}
    + \frac{1}{Z}\frac{\partial^2Z}{\partial z^2}=0
\end{equation*}
Since only last term is the function of $z$ alone, we can safely say that it is a constant. Therefore, we define 
\begin{equation*}
    \frac{1}{Z}\frac{\partial^2Z}{\partial z^2}=K^2\implies Z=Ae^{Kz}+Be^{-KZ}
\end{equation*}
Substituting this value and multiplying by $r^2$, we have
\begin{equation*}
    \frac{r}{R}\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +\frac{1}{\Phi } \frac{\partial^2\Phi}{\partial \phi^2}
    +K^2r^2=0
\end{equation*}
Now we see that the second term is constant. We define 
\begin{equation*}
    \frac{1}{\Phi}\frac{\partial^2 \Phi}{\partial \phi}=-n^2\implies \Phi=C\sin n\theta +D\cos n\theta
\end{equation*}
where $n$ is an integer. The reason for said separation constant is due to periodicity. For a position in polar coordinate, we denote them as $\theta+2n\pi$. Hence, for a most physical reason, the position $\theta$ and $\theta+2n\pi$ must give the same result, which is possible if the solution is periodic with period of $2\pi$. Finally, we substitute this and multiplying with $R$ to obtain the radial solution
\begin{equation*}
    r\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +(K^2r^2-n^2)R=0
\end{equation*}
This is Bessel function, in particular
\begin{equation*}
    R=\sum_{m=0}^{\infty}E_mJ_m(Kr)+\sum_{m=0}^{\infty}F_mN_m(Kr)
\end{equation*}
Now, putting it all together, we have the most general solution for the Laplace's equation in cylindrical domain 
\begin{multline*}
    u=\sum_{m=0}^{\infty}\left[A_me^{Kz}+B_me^{-KZ}\right]\left[C_m\sin n\theta +D_m\cos n\theta\right]\\
    \left[E_mJ_m(Kr)+F_mN_m(Kr)\right]
\end{multline*}

\subsection*{Poisson’s Equation}
Consider the same scalar function $u$ as the case of Laplace's equation, however we have a region containing mass, electric charge, or sources of heat or fluid denoted by $f(x,y,z)$. Poisson's equation is written as 
\begin{equation*}
    \nabla^2 u=f(x,y,z)
\end{equation*}

\subsection*{Heat Flow or Diffusion Equation}
Now suppose that the temperature is non-steady. The flow of temperature is governed by the equation 
\begin{equation*}
    \nabla^2 u=\frac{1}{\alpha}\frac{\partial u}{\partial t}
\end{equation*}
where $\alpha$ is a constant called the diffusivity.

\subsection*{Wave Equation}
Here $u$ may represent the displacement from equilibrium; in electricity it may be the current or potential along a transmission line; or it may be a component of \textbf{E} or \textbf{B} in an electromagnetic wave. The equation is written as 
\begin{equation*}
    \nabla^2u=\frac{1}{v^2}\frac{\partial^2u}{\partial t^2}
\end{equation*}

\subsection*{Helmholtz Equation}
Helmholtz's equation is the spatial part of either diffusion or wave equation
\begin{equation*}
    \nabla^2F+k^2F=0
\end{equation*}

\subsection*{Schrödinger's Equation}
Also known as the wave function equation of quantum mechanics
\begin{equation*}
    -\frac{\hbar^2}{2m}\nabla^2\Psi+V\Psi= i\hbar\frac{\partial \Psi}{\partial t}
\end{equation*}
\end{document}