\documentclass[../../../main.tex]{subfiles}
\begin{document}
\subsection{First Order}
\subsubsection{First Order ODE.} Written in the form
\begin{equation*}
    y'+P(x)y=Q(x)
\end{equation*}
where $P$ and $Q$ are functions of $x$ has the solution
\begin{align*}
    ye^I & =\int Q e^I\;dx+c             \\
    y    & =e^{-I}\int Q e^I\;dx+ce^{-I}
\end{align*}
where\begin{equation*}
    I=\int P\;dx
\end{equation*}

\subsubsection{Bernoulli Equation.} The differential equation
\begin{align*}
    y'+P(x)y=Q(x)y^n
\end{align*}
where $P$ and $Q$ are functions of $x$.
It also can be written as
\begin{equation*}
    z'+(1-n)Pz=(1 - n)Q
\end{equation*}
where
\begin{align*}
    z = y^{1-n}
\end{align*}
This is now a first-order linear equation which we can solve as we did the linear equations above.

\subsubsection{Exact Equations.}  $P (x, y) dx+Q(x, y)dy$ is an exact differential [the differential of $F (x, y)$, or $P dx + Q dy = dF$] if
\begin{equation*}
    \pardf P=\pardf Q
\end{equation*}
and the solution is
\begin{equation*}
    F (x, y) = \text{constant}
\end{equation*}
An equation which is not exact may often be made exact by multiplying it by
an appropriate factor.

\subsubsection{Homogeneous Equations.} A homogeneous function of $x$ and $y$ of degree $n$ means a function which can be written as $x^nf (y/x)$.
An equation in the form
\begin{equation*}
    P (x, y) dx + Q(x, y) dy = 0
\end{equation*}
where $P$ and $Q$ are homogeneous functions of the same degree is called homogeneous.
Thus,
\begin{equation*}
    y'=\df y=-\frac{P (x, y)}{Q(x, y)}-f(\frac{y}{x})
\end{equation*}
This suggests that we solve homogeneous equations by making the change of variables
\begin{align*}
    y=xv\quad\text{with}\quad v=\frac{y}{x}
\end{align*}

\subsection{Second Order}
\subsubsection{Second Order with Zero Right-Hand Side.}
Equation of the form
\begin{equation*}
    (D-a)(D-b)y=0,\quad a \neq b
\end{equation*}
has the Solution
\begin{align*}
    y = c_1e^{ax} + c_2e^{bx}
\end{align*}

Equation of the form
\begin{equation*}
    (D-a)(D-a)y=0,\quad a \neq b
\end{equation*}
has the Solution
\begin{align*}
    y = (Ax + B)e^{ax}
\end{align*}

Now suppose the roots of the auxiliary equation are $\alpha \pm i\beta $.
The solution is now
\begin{align*}
    y & =Ae^{(\alpha + i\beta)}x + Be^{(\alpha - i\beta)}x  \\
      & =e^{\alpha x}(Ae^{i\beta x} + Be^{-i\beta x})       \\
      & = e^{\alpha x}(c_1 \sin \beta x + c_2 \cos \beta x) \\
      & = ce^{\alpha x} \sin(\beta x + \gamma)
\end{align*}
where $\alpha,\;\beta,\;\gamma,\;c,\;c_1,\;c_2$ are different constant.

\subsubsection{Second Order with Nonzero Right-hand Side.} The equation
\begin{align*}
    a_2\seconddf y+a_1\df y+a_0y=f(x) \\
    \seconddf y+a_1\df y+a_0y=F(x)
\end{align*}
has the solution of the form
\begin{equation*}
    y = y_c + y_p
\end{equation*}
where the complementary function $y_c$ is the general solution of the homogeneous
equation (when right-hand side is equal to zero) and $y_p$ is a particular solution, that is when the right-hand side is equal to $f(x)$ or $F(x)$.
The simplest method solving them is by Inspection and Successive Integration of Two First-Order Equations.

\subsubsection{Exponential Right-Hand Side.}
Suppose we have $F (x) = ke^{cx}$, or
\begin{equation*}
    (D - a)(D - b)y =ke^{cx}
\end{equation*}
then, we find a particular solution by
assuming a solution of the form:
\begin{align*}
    y_p=
    \begin{cases}
        Ce^{cx} \quad    & \text{if c is not equal to either a or b;} \\
        Cxe^{cx} \quad   & \text{if c equals a or b, a  $\neq$ b;}    \\
        Cx^2e^{cx} \quad & \text{if c = a = b.}
    \end{cases}
\end{align*}

\subsubsection{Complex Exponential.} To find a particular solution of
\begin{equation*}
    (D - a)(D - b)y=\begin{cases}
        k\sin \alpha x, \\
        k\cos \alpha x,
    \end{cases}
\end{equation*}
first solve
\begin{equation*}
    (D - a)(D - b)y=ke^{i\alpha x}
\end{equation*}
then take the real or imaginary part.

\subsubsection{Method of Undetermined Coefficients.} To find a particular solution of
\begin{equation*}
    (D - a)(D - b)y=e^{cx}P_n(x)
\end{equation*}
where $P_n(x)$ is a polynomial of degree n is
\begin{align*}
    y_p=
    \begin{cases}
        e^{cx}Q_n(x) \quad    & \text{if c is not equal to either a or b;} \\
        xe^{cx}Q_n(x) \quad   & \text{if c equals a or b, a  $\neq$ b;}    \\
        x^2e^{cx}Q_n(x) \quad & \text{if c = a = b.}
    \end{cases}
\end{align*}
where $Q_n(x)$ is a polynomial of the same degree as $P_n(x)$ with undetermined
coefficients to be found to satisfy the given differential equation.

\subsubsection{Euler's equation.} Has the form of
\begin{equation*}
    a_2x^2\frac{d^2y}{dx^2} +a_1x\frac{dy}{dx} +a_0y=f(x)
\end{equation*}
By substituting $x=e^z$, we obtain the following equation
\begin{equation*}
    a_2\frac{d^2y}{dx^2} +(a_1-a_2)\frac{dy}{dz} +a_0y=f(e^z)
\end{equation*}

\paragraph*{Proof.} First, we compute the first derivative of $y$
\begin{equation*}
    \frac{dy}{dz}=\frac{dy}{dx}\frac{dx}{dz}=e^z\frac{dy}{dx}=x\frac{dy}{dx}
\end{equation*}
Then the second
\begin{align*}
    \frac{d^2y}{dz^2} & =\frac{d}{dz}\left(e^z\frac{dy}{dx}\right)=e^z\frac{dy}{dx} + e^z\frac{d}{dz}\left(\frac{dy}{dx}\right) \\
    \frac{d^2y}{dz^2} & =\frac{dy}{dz}+x\frac{d}{dx}\left(\frac{dy}{dx}\right)\frac{dx}{dz}=\frac{dy}{dx}+x^2\frac{d^2y}{dx^2}
\end{align*}
And substituting it
\begin{align*}
    a_2 \left(\frac{d^2y}{dz^2}-\frac{dy}{dx}\right)+ a_1\frac{dy}{dz} +a_0y & =f(e^z) \\
    a_2\frac{d^2y}{dz^2}+ (a_1-a_2)\frac{dy}{dz} +a_0y                       & =f(e^z)
\end{align*}

\subsubsection{Principle of Superposition.} The easiest way of handling a complicated right-hand side: Solve a separate equation for each different exponential and add the solutions.
The fact that this is correct for a linear equation is often called the principle of superposition.

Note that the principle holds only for linear equations.

\subsubsection{Fourier Series.}
Suppose that the driving force $f(x)$ is periodic, we then can expand the function using Fourier Series.
The equation
\begin{equation*}
    a_2\seconddf y+a_1\df y+a_0y=f(x)=\sum_{-\infty}^{\infty}c_ne_{inx}
\end{equation*}
can be solved by solving
\begin{equation*}
    a_2\seconddf y+a_1\df y+a_0y=c_ne_{inx}
\end{equation*}
then add the solutions for all $n$ (applying principle of superposition), and we have the solution of first the equation.

\subsection{Coupled First Order Equation}
Any system of order \(m\) can be converted to first order by introducing derivatives as additional variables. The general first-order form is
A coupled ordinary differential equation (ODE) system is treated by rewriting it as a first-order vector ODE.
Consider the linear autonomous system
\begin{equation*}
    \frac{d}{dt}
    \begin{bmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{bmatrix}
    =
    \begin{bmatrix} a_{11}(t) & a_{12}(t) & \cdots & a_{1n}(t) \\ a_{21}(t) & a_{22}(t) & \cdots & a_{2n}(t) \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1}(t) & a_{n2}(t) & \cdots & a_{nn}(t) \end{bmatrix}
    \begin{bmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{bmatrix}
    +
    \begin{bmatrix} g_1(t) \\ g_2(t) \\ \vdots \\ g_n(t) \end{bmatrix}
\end{equation*}
or
\begin{equation*}
    \frac{d\mathbf{u}}{dt}=A\mathbf{u}+\mathbf{g}(t)
\end{equation*}
with constant matrix \(A\in\mathbb{R}^{n\times n}\) and inhomogeneity \(\mathbf{g}(t)\).
$g(t)$ may be a constant vector, a function of $t$, or any prescribed external input.

If \(\mathbf{g}(t)\equiv 0\), the solution is
\[
    \mathbf{u}(t)=\exp(A(t-t_0))\,\mathbf{u}_0,
\]
where \(\exp(A\tau)\) is the matrix exponential. If \(\mathbf{g}\neq 0\), variation of constants yields
\[
    \mathbf{u}(t)=\exp(A(t-t_0))\,\mathbf{u}_0
    + \int_{t_0}^{t} \exp(A(t-s))\,\mathbf{g}(s)\,ds.
\]

If \(A\) is diagonalizable, write \(A=V\Lambda V^{-1}\) with \(\Lambda=\operatorname{diag}(\lambda_i)\). Then
\[
    \exp(A\tau)=V\,\operatorname{diag}(e^{\lambda_i \tau})\,V^{-1}.
\]
If \(A\) has a Jordan form, one uses the exponential of Jordan blocks.

\subsubsection{Proof.}
Let the linear system be
\[
    \dot{x}(t)=A\,x(t)+g(t),
\]
where \(A\) is a constant \(n\times n\) matrix and \(g(t)\) is a given vector function.

Define the fundamental matrix \(\Phi(t)\) as the unique solution of
\[
    \dot{\Phi}(t)=A\,\Phi(t), \qquad \Phi(0)=I.
\]
Then \(\Phi(t)=e^{At}\).

Assume a solution of the inhomogeneous system of the form
\[
    x(t)=\Phi(t)\,c(t),
\]
where \(c(t)\) is an unknown vector function. Differentiating yields
\[
    \dot{x}(t)=\dot{\Phi}(t)c(t)+\Phi(t)\dot{c}(t).
\]
Using \(\dot{\Phi}(t)=A\Phi(t)\) gives
\[
    \dot{x}(t)=A\Phi(t)c(t)+\Phi(t)\dot{c}(t)
    =A x(t)+\Phi(t)\dot{c}(t).
\]
Substitute this expression into the differential equation:
\[
    A x(t)+\Phi(t)\dot{c}(t)=A x(t)+g(t).
\]
Cancel \(A x(t)\) to obtain
\[
    \Phi(t)\dot{c}(t)=g(t).
\]
Since \(\Phi(t)\) is invertible, multiply by \(\Phi(t)^{-1}\):
\[
    \dot{c}(t)=\Phi(t)^{-1}g(t).
\]
Integrate from \(0\) to \(t\):
\[
    c(t)=c(0)+\int_{0}^{t}\Phi(s)^{-1}g(s)\,ds.
\]
Using the initial condition \(x(0)=\Phi(0)c(0)=I\,c(0)\), one obtains \(c(0)=x(0)\).

Substitute into \(x(t)=\Phi(t)c(t)\):
\[
    x(t)=\Phi(t)x(0)+\Phi(t)\int_{0}^{t}\Phi(s)^{-1}g(s)\,ds.
\]
Use the identity \(\Phi(t)\Phi(s)^{-1}=e^{A(t-s)}\) to rewrite:
\[
    x(t)=e^{A t}x(0)
    +\int_{0}^{t} e^{A(t-s)} g(s)\,ds.
\]
This expression is the general solution of the inhomogeneous linear system.


\subsection{Laplace Transform}
We define $\mathcal{L}(f )$, the Laplace transform of $f (t)$ [also written $F (p)$ since it is a function of $p$], by the equation
\begin{equation*}
    \mathcal{L}(f)=F(P)=\int_{0}^{\infty}f(t)e^{-pt};dt
\end{equation*}

\subsubsection{Laplace transform 101.} How 2 Laplace transform in 5 steps!
\begin{enumerate}
    \item Transform!
    \item Do algebra!
    \item Inverse!
    \item $\dots$
    \item Profit!
\end{enumerate}

\subsection{Convolution}
\subsubsection{Definition.} The integral
\begin{equation*}
    g*h=\int_{0}^{t}g(t-\tau)h(\tau)d(\tau)=\int_{0}^{t}g(\tau)h(t-\tau)d(\tau)
\end{equation*}
is called the convolution of g and h (or the resultant or the Faltung).
Now suppose that we have
\begin{equation*}
    Ay' + By' + Cy = f (t), \quad y0 = y'0 = 0
\end{equation*}
take the Laplace transform of each term, substitute the initial conditions, and solve for Y
\begin{equation*}
    Y=\frac{F(p)}{A(p + a)(p + b)}=T(p)F(p)
\end{equation*}
Then $y$ the inverse transform of $Y$ in is the inverse transform of a product of two functions whose inverse transforms we know.
Let $G(p)$ and $H(p)$ be the transforms of $g(t)$ and $h(t)$
\begin{equation*}
    G(p)H(p)=\mathcal{L}(g(t)\cdot h(t))=\mathcal{L}(g*h)
\end{equation*}
Thus
\begin{equation*}
    y=\int_{0}^{t}g(t-\tau)h(\tau)d(\tau)
\end{equation*}
Observe from $\mathcal{L}34$ that we may use either $g(t - \tau )h(\tau )$ or $g(\tau )h(t - \tau )$ in the integral.
It is well to choose whichever form is easier to integrate; it is best to put$ (t - \tau )$ in the simpler function.

\subsubsection{Fourier Transform of a Convolution.} Let $g_1(\alpha)$ and $g_2(\alpha)$ be the Fourier transforms of $f_1(x)$ and $f_2(x)$
\begin{align*}
    g_1(\alpha)\cdot g_2(\alpha) & =\frac{1}{2\pi}\int_{-\infty}^{\infty}f_1(v)e^{-i\alpha v}dv\cdot \frac{1}{2\pi}\int_{-\infty}^{\infty}f_1(u)e^{-i\alpha u}du \\
                                 & =\biggl(\frac{1}{2\pi}\biggr)^2\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f_1(v)f_2(u)e^{-i\alpha (v+u)}dvdu
\end{align*}
Next we make the change of variables $x = v + u$, $dx = dv$, in the v integral
\begin{align*}
    g_1(\alpha)\cdot g_2(\alpha) & = \biggl(\frac{1}{2\pi}\biggr)^2\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f_1(x-u)f_2(u)e^{-i\alpha x}dvdu                \\
                                 & = \biggl(\frac{1}{2\pi}\biggr)^2\int_{-\infty}^{\infty}e^{-i\alpha x}\biggl[\int_{-\infty}^{\infty}f_1(x-u)f_2(u)\;du\biggr]dx
\end{align*}
if we define the term in the square parenthesis as convolution, we get
\begin{align*}
    g_1(\alpha)\cdot g_2(\alpha) & =\frac{1}{2\pi}\biggl(\int_{-\infty}^{\infty}f_1*f_2e^{-i\alpha x}dx\biggr) \\
                                 & =\frac{1}{2\pi}\cdot\text{Fourier transform of }f_1*f_2
\end{align*}
In other words
\begin{equation*}
    g_1\cdot g_2\text{ and }f_1*f_2\text{ are a pair of Fourier transforms}
\end{equation*}
and by symmetry
\begin{equation*}
    g_1* g_2\text{ and }f_1\cdot f_2\text{ are a pair of Fourier transforms}
\end{equation*}

\subsection{Rodrigues' Formula}
The second order Sturm-Liouville differential equation
\begin{align*}
    \frac{d}{dx} \left[p(x) \frac{dy}{dx}\right] + q(x)y = -\lambda_n w(x) y
\end{align*}
Has the solution $y=y_n$, with
\begin{equation*}
    y_n=\frac{1}{w(x)}\frac{d^n}{dx^n}[w(x)p(x)^n]
\end{equation*}

Alternatively, the Sturm-Liouville equation can be written as
\begin{equation*}
    a(x)y''+b(x)y'+c(x)y=-\lambda_n \tilde{w}(x)y
\end{equation*}
then we define the integrating factor such that $w(x)=\mu(x)\tilde{w}(x)$, where
\begin{equation*}
    \mu(x)=\frac{1}{a(x)}\exp\left(\int_0^x \frac{b(x)}{a(x)}dx\right)
\end{equation*}
Using this definition, the solution reads
\begin{equation*}
    y_n=\frac{1}{\mu(x)\tilde{w}(x)}\frac{d^n}{dx^n}[\mu(x)\tilde{w}(x)a(x)^n]
\end{equation*}

In most cases $c=0$,$\tilde{w}(x)=1$ and the equation takes the form of
\begin{equation*}
    a(x)y''+b(x)y'+\lambda_ny=0
\end{equation*}
Then the solution reads
\begin{equation*}
    y_n=\frac{1}{\mu(x)}\frac{d^n}{dx^n}[\mu(x)a(x)^n]
\end{equation*}

\subsubsection{Rewriting.} First we begin with the form
\begin{equation*}
    ay''+by'+cy'=-\lambda \tilde{w}y
\end{equation*}
Multiply by the integrating factor
\begin{equation*}
    \mu(ay''+by'+cy')=-\lambda \mu \tilde{w}y
\end{equation*}
To equating this form with the Sturm-Liouville form
\begin{equation*}
    py''+p'y'+qy=-\lambda w y
\end{equation*}
we define
\begin{equation*}
    p\equiv\mu a,\;p'\equiv \mu b,\;q\equiv\mu c,\;w=\mu\tilde{w}
\end{equation*}
From this definition, we see
\begin{equation*}
    \frac{d}{dx}\mu a=\mu' a+\mu a'=\mu b
\end{equation*}
Dividing by the integrating factor and solving for the integrating factor
\begin{align*}
    \frac{\mu'}{\mu}a+a'  & =b                                     \\
    \frac{\mu'}{\mu}      & =\frac{b-a'}{a}                        \\
    \int\frac{1}{\mu}d\mu & =\int\frac{b-a'}{a}dx                  \\
    \mu                   & =\exp\left(\int\frac{b-a'}{a}dx\right)
\end{align*}
Since
\begin{equation*}
    \int\frac{a'}{a}dx=\int\frac{1}{a}da=\ln a
\end{equation*}
we can write
\begin{equation*}
    \mu=\frac{1}{a}\exp\left(\int\frac{b}{a}dx\right)
\end{equation*}

Therefore, we have the solution
\begin{equation*}
    y_n=\frac{1}{\mu\tilde{w}}\frac{d^n}{dx^n}[\mu\tilde{w}(\mu a)^n]
\end{equation*}
This should be the correct solution, however it is not.
I don't know why, but the solution is actually
\begin{equation*}
    y_n=\frac{1}{\mu\tilde{w}}\frac{d^n}{dx^n}[\mu\tilde{w}a^n]
\end{equation*}
I wonder why the term $\mu^n$ disappears...

\subsection{Frobenius Method}
By using this method, we assume that the solution has the form of power series
\begin{equation*}
    y=\sum_{n=0}^{\infty} a_nx^{n+s}
\end{equation*}
We also assume that the first coefficient, that is $a_0$, is not zero.
Computing the derivative of $y$, we obtain
\begin{align*}
    y   & =\sum_{n=0}^{\infty} a_nx^{n+s}                \\
    y'  & =\sum_{n=0}^{\infty} (n+s) a_nx^{n+s-1}        \\
    y'' & =\sum_{n=0}^{\infty} (n+s) (n+s-1)a_nx^{n+s-2}
\end{align*}

\subsubsection{Frobenius 101.} How 2 solve differential equation using generalized power series in 5 steps!
\begin{enumerate}
    \item Tabulate!
    \item Find the column in terms of $x^{n+s}$ $x^s\rightarrow$!
    \item Factor the coefficients that contain $a_0\rightarrow$ and solve the indicial equation!
    \item Solve it in terms of $a_n=-a_{n-2}$! (not factorial!)
    \item As a check, put $n=2$ at $a_n$ not $n=0$! (also not factorial!)
\end{enumerate}

\subsection{Bessel Function}
The first kind of Bessel function is written as
\begin{align*}
    J_p(x)     & =\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n+p}}{\Gamma(n+1)\Gamma(n+p+1)} \\
    J_{-p} (x) & =\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n-p}}{\Gamma(n+1)\Gamma(n-p+1)}
\end{align*}
While the second kind is
\begin{equation*}
    N_p(x)=\frac{\cos(\pi p)J_p(x)-J_{-p}(x)}{\sin(\pi p)}
\end{equation*}

The Bessel function is used to solve the Bessel's equation of order $p$
\begin{equation*}
    x^2 y'' + xy' + (x^2- p^2 )y = 0
\end{equation*}
with the solution written as
\begin{equation*}
    y=AJ_p(x)+BN_p(x)
\end{equation*}
Another form of Bessel's equation is
\begin{equation*}
    x(xy')' + (K^2x^2- p^2 )y = 0
\end{equation*}
and the solution is
\begin{equation*}
    y=AJ_p(Kx)+BN_p(Kx)
\end{equation*}
Another equation that can be solved by Bessel function
\begin{equation*}
    y''+ \frac{1-2a}{x}y'+ \left[(bcx^{c-1})^2+ \frac{a^2-p^2c^2}{x^2}\right]y=0
\end{equation*}
The solution is
\begin{equation*}
    y=x^a Z_p(bx^c)
\end{equation*}
where $a,\;b,\;c,\;p$ are constant and $Z$ denote $J$ or $N$ or any linear combination of them.

The generating function, expression that encodes an infinite sequence, for Bessel function is
\begin{equation*}
    \exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right] =\sum_{p=-\infty}^{\infty}J_n(x)t^p
\end{equation*}

\subsubsection{Series representation derivation.}
First we write the Bessel's equation as
\begin{equation*}
    x(xy')'+ (x^2-p^2)y=0
\end{equation*}
By the Frobenius' method
\begin{align*}
    y      & =\sum_{n=0}^{\infty} a_nx^{n+s}           \\
    xy'    & =\sum_{n=0}^{\infty} a_n(n+s) x^{n+s}     \\
    (xy')' & =\sum_{n=0}^{\infty} a_n(n+s)^2 x^{n+s-1}
\end{align*}
and
\begin{align*}
    x(xy')' & =\sum_{n=0}^{\infty} a_n(n+s)^2 x^{n+s} \\
    x^2y    & =\sum_{n=0}^{\infty} a_n x^{n+s+2}      \\
    -p^2y   & =-\sum_{n=0}^{\infty} a_np^2x^{n+s}
\end{align*}
Tabulate them

\begin{table}[h]
    \centering
    \caption{Table}
    \begin{tabular}{cccc }
        \toprule
                  & $x^{n+s}$     & $x^s$     & $x^{s+1}$    \\
        \midrule
        $x(xy')'$ & $a_n(n+s)^2 $ & $a_0s^2$  & $a_1(s+1)^2$ \\
        $x^2y $   & $a_{n-2}$     & $- $      & $-$          \\
        $-p^2y$   & $-a_np^2$     & $-a_0p^2$ & $-a_1p^2$    \\
        \bottomrule
    \end{tabular}
\end{table}

From this we have the indicial equation
\begin{equation*}
    s^2-p^2=0\implies s=\pm p
\end{equation*}

And the general formula of the coefficient
\begin{equation*}
    a_n=-\frac{a_{n-2}}{(n+s)^2-p^2}
\end{equation*}
For $s=\pm p$ and odd $n$, the coefficient is zero; proved by
\begin{equation*}
    a_1\left[(s+1)^2-p^2\right]=a_1\left[2p+1\right]=0\implies a_1=0
\end{equation*}

We begin first for the case $s=p$.
The coefficient is given by
\begin{equation*}
    a_n=-\frac{a_{n-2}}{(n+p)^2-p^2}=-\frac{a_{n-2}}{n^2-2np}=-\frac{a_{n-2}}{n(n+2p)}
\end{equation*}
For even $n$, we write
\begin{equation*}
    a_{2n}=-\frac{a_{2n-2}}{2n(2n+2p)}= -\frac{a_{2n-2}}{2^2n(n+p)}
\end{equation*}
The coefficients for few odd $n$ are as follows.
\begin{align*}
    a_2 & =-\frac{a_0}{2^2(p+1)}=-\frac{a_0\Gamma(p+1)}{2^2\Gamma(p+2)}                                            \\
    a_4 & =-\frac{a_2}{2^22(p+2)}=-\frac{a_2\Gamma(p+2)}{2^22\Gamma(p+3)}=\frac{a_0\Gamma(p+1)}{2^42!\Gamma(p+3)}  \\
    a_6 & =-\frac{a_4}{2^23(p+3)}=-\frac{a_4\Gamma(p+3)}{2^23\Gamma(p+4)}=-\frac{a_0\Gamma(p+1)}{2^63!\Gamma(p+4)}
\end{align*}

The solution is written
\begin{align*}
    y= & \;\sum_{n=0}^{\infty} a_nx^{n+p}=a_0x^p+a_2x^{p+2}+a_4 x^{p+4}+a_6x^{p+6}                                                                                    \\
    =  & \;a_0x^p\Gamma(p+1)\bigg[\frac{1}{\Gamma(p+1)}- \frac{(x/2)^2}{\Gamma(p+2)}+\frac{(x/2)^4}{2!\Gamma(p+3)}                                                    \\
       & \quad- \frac{(x/2)^6}{3!\Gamma(p+4)}+\dots\bigg]                                                                                                             \\
    =  & \;a_02^p\Gamma(p+1)\left(\frac{x}{2}\right)^p\bigg[\frac{1}{\Gamma(1)\Gamma(p+1)}- \frac{(x/2)^2}{\Gamma(2)\Gamma(p+2)}+\frac{(x/2)^4}{\Gamma(3)\Gamma(p+3)} \\
       & \quad- \frac{(x/2)^6}{\Gamma(4)\Gamma(p+4)}+\dots\bigg]
\end{align*}
If we define
\begin{equation*}
    a_0=\frac{1}{2p\Gamma(p+1)}
\end{equation*}
then the solution, which is defined as $J_p(x)$, is written
\begin{multline*}
    J_p(x)=\frac{(x/2)}{\Gamma(1)\Gamma(p+2)}-\frac{(x/2)^{p+2}}{\Gamma(3)\Gamma(p+3)} +\frac{(x/2)^{p+4}}{\Gamma(3)\Gamma(p+3)} \\
    -\frac{(x/2)^{p+6}}{\Gamma(4)\Gamma(p+4)} +\dots
\end{multline*}
or
\begin{equation*}
    J_p(x)=\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n+p}}{\Gamma(n+1)\Gamma(n+p+1)}
\end{equation*}

Next we consider the solution for $s=-p$.
Since the steps are the same, we only need to change the sign of $p$.
The solution is written
\begin{equation*}
    J_{-p} (x)=\sum_{n=0}^{\infty}\frac{(-1)^n(x/2)^{2n-p}}{\Gamma(n+1)\Gamma(n-p+1)}
\end{equation*}

As an aside, for the Bessel equation written in the form
\begin{equation*}
    x^2y'' +xy' + (K^2x^2- p^2 )y = 0
\end{equation*}
All the terms are unchanged except the term
\begin{equation*}
    K^2x^2y=\sum_{n=0}^{\infty} a_n K^2x^{n+s+2}
\end{equation*}
This will result the change of argument in the Bessel equation from $Z(x)$ into $Z(Kx)$.

\subsubsection{Generating function proof.} Proved by writing it out.
\begin{align*}
    \exp\left[\frac{xt}{2}\right] \exp\bigg[-\frac{x}{2t}\bigg] & =\sum_{n=0}^{\infty}\frac{(xt/2)^n}{n!}\sum_{m=0}^{\infty} \frac{(-x/2t)^m}{m!}                 \\
    \exp\left[\frac{xt}{2}\right] \exp\bigg[-\frac{x}{2t}\bigg] & =\sum_{n=0}^{\infty}\sum_{m=0}^{\infty}(-1)^m\frac{t^{n-m}}{n!m!}\left(\frac{x}{2}\right)^{n+m}
\end{align*}
We then define $p\equiv n-m$ to shift the indices
\begin{equation*}
    \exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right]= \sum_{p=-\infty}^{\infty}\sum_{m=0}^{\infty}\frac{(-1)^m(x/2)^{p+2m}}{(p+m)!m!}t^p=\sum_{p=-\infty}^{\infty}J_p(x)t^p
\end{equation*}

\subsubsection{Recursive relation.} Here are few relations of Bessel function with its derivative.
\begin{gather*}
    J_{p-1}(x)+J_{p+1}(x)=\frac{2p}{x}J_p(x)\\
    J_{p-1}(x)- J_{p+1}(x)=2J'_p(x)\\
    \frac{d}{dx}[x^pJ_p(x)]=x^pJ_{p-1}(x)\\
    \frac{d}{dx}[x^{-p}J_p(x)]=-x^{-p}J_{p+1}(x)\\
    J'_p(x)=-\frac{p}{x}J_p(x)+J_{p-1}(x)=\frac{p}{x}J_p(x)-J_{p+1}(x)
\end{gather*}
And bonus relation that only apply for integral $p$
\begin{gather*}
    J_{-p}(x)=(-1)^pJ_p(x)\\
    J_p(-x)=(-1)^pJ_p(x)
\end{gather*}


\paragraph*{First relation proof.} Differentiate the expression for generating function with respect to $t$
\begin{align*}
    \frac{x}{2}\left(1+\frac{1}{t^2}\right)\exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right] & =\sum_{p=-\infty}^{\infty}pJ_p(x)t^{p-1}            \\
    \sum_{p=-\infty}^{\infty}\left[J_p(x)+J_{p-2}(x)\right]t^p                                    & = \sum_{p=-\infty}^{\infty}\frac{2p}{x}J_{p+1}t^{p}
\end{align*}
Taking the constant for the term $t^p$, we have
\begin{equation*}
    J_p(x)+J_{p-2}(x)=\frac{2p}{x}J_{p+1}
\end{equation*}

\paragraph*{Second relation proof.} Differentiate with respect to $x$ instead
\begin{align*}
    \frac{1}{2}\left(t-\frac{1}{t}\right)\exp\left[\frac{x}{2}\left(t-\frac{1}{t}\right)\right] & =\sum_{p=-\infty}^{\infty}J'_p(x)t^{p} \\
    \sum_{p=-\infty}^{\infty}\left[J_{p+1}(x)+J_{p-1}(x)\right]t^p                              & = \sum_{p=-\infty}^{\infty}2J'_pt^{p}
\end{align*}
and as before, we have
\begin{equation*}
    J_{p+1}(x)+J_{p-1}(x)=2J'_p
\end{equation*}

\paragraph*{Third relation proof.} Simply evaluate the derivative and use both first and second relation
\begin{align*}
    \frac{d}{dx}\left[x^pJ_p(x)\right] & = \frac{x^p}{2}\left[J_{p-1}(x)+J_{p+1}(x)\right]+\frac{x^p}{2}\left[J_{p-1}(x)-J_{p+1}(x)\right] \\
    \frac{d}{dx}\left[x^pJ_p(x)\right] & =x^pJ_{p-1}(x)
\end{align*}

\paragraph*{Fourth relation proof.} The same as the third
\begin{align*}
    \frac{d}{dx}\left[x^{-p}J_p(x)\right] & = -\frac{x^{-p}}{2}\left[J_{p-1}(x)+J_{p+1}(x)\right]+\frac{x^p}{2}\left[J_{p-1}(x)-J_{p+1}(x)\right] \\
    \frac{d}{dx}\left[x^{-p}J_p(x)\right] & =x^{-p}J_{p+1}(x)
\end{align*}

\paragraph*{Fifth relation proof.} Add both first and second relation to obtain the middle side
\begin{align*}
    2J_{p-1}(x) & =\frac{2p}{x}J_p(x)+2J'_p(x)  \\
    J'_{p}(x)   & =J_{p-1}(x)-\frac{p}{x}J_p(x)
\end{align*}
and subtract to obtain the right side
\begin{align*}
    2J_{p+1}(x) & =\frac{2p}{x}J_p(x)-2J'_p(x)  \\
    J'_{p}(x)   & =\frac{p}{x}J_p(x)-J_{p+1}(x)
\end{align*}

\subsubsection{Orthogonality.} Suppose $\alpha$ and $\beta$ are the zeros of the Bessel function order $p$.
We can say that the function $\sqrt{x}J_p(\alpha x)$ is orthogonal with itself on $(0,1)$.
We can also say that the functions $J_p^2(\alpha x)$ are orthogonal with respect with weight function $x$.
Thus, we write
\begin{equation*}
    \int_{0}^{1}xJ_p(\alpha x)J_p(\beta x)\;dx=\begin{cases}
        0                                                                                         & \alpha\neq \beta \\
        \dfrac{1}{2}{J'_p}^2(\alpha)=\dfrac{1}{2}J_{p+1}^2(\alpha) =\dfrac{1}{2}J_{p-1}^2(\alpha) & \alpha=\beta
    \end{cases}
\end{equation*}
We can change the integration limit by substituting $x=r/a$
\begin{equation*}
    \int_{0}^{a}rJ_p\left(\alpha \frac{r}{a}\right)J_p\left(\beta \frac{r}{a}\right)\;dr=\begin{cases}
        0                                                                                               \\
        \qquad \alpha\neq \beta                                                                         \\
        \dfrac{a^2}{2}{J'_p}^2(\alpha)=\dfrac{a^2}{2}J_{p+1}^2(\alpha) =\dfrac{a^2}{2}J_{p-1}^2(\alpha) \\
        \qquad\alpha=\beta
    \end{cases}
\end{equation*}

\paragraph*{Proof.} To prove the relation orthogonality of the Bessel function on $(0,1)$ with respect to the weight function $x$, consider the equations
\begin{align*}
    x(xy')'+(\alpha^2x^2-p^2)y & =0 \\
    x(xy')'+(\beta^2x^2-p^2)y  & =0
\end{align*}
which are solved by the functions $J_p(\alpha x)$ and $J_p(\beta x)$ respectively.
For brevity's sake, we define $J_p(\alpha x)\equiv u$,  $J_p(\beta x)\equiv v$ and we write
\begin{align*}
    x(xu')'+(\alpha^2x^2-p^2)u & =0 \\
    x(xv')'+(\beta^2x^2-p^2)v  & =0
\end{align*}
Multiplying the first equation with $u$ and the second with $v$
\begin{align*}
    xv(xu')'+(\alpha^2x^2-p^2)uv & =0 \\
    xu(xv')'+(\beta^2x^2-p^2)vu  & =0
\end{align*}
Subtracting them
\begin{align*}
    xv(xu')'-xu(xv')'+(\alpha^2-p^2)x^2uv & =0 \\
    v(xu')'-u(xv')'+(\alpha^2-p^2)xuv     & =0
\end{align*}
Note that we can write the first two terms as
\begin{align*}
    \frac{d}{dx}\left(vxu'-uxv'\right) & =x'xu'+v(xu)'-u'xv'-u(xv')' \\
                                       & =v(xu')'-u(xv')'
\end{align*}
On integrating it within $(0,1)$
\begin{equation*}
    \left(vxu'-uxv'\right)\bigg|_0^1+\int_{0}^{1}(\alpha^2-p^2)xuv\;dx=0
\end{equation*}
By the definition
\begin{equation*}
    J_p(\beta)J_p'(\alpha) -J_p(\alpha)j_p'(\beta) +\int_{0}^{1}(\alpha^2-p^2)xJ_p(\alpha)j_p(\beta)\;dx=0
\end{equation*}
where the value at lower limit of those two terms are zero.
Since both $\alpha$ and $\beta$ are the zeros of the Bessel functions
\begin{equation*}
    \int_{0}^{1}(\alpha^2-p^2)xJ_p(\alpha)J_p(\beta)\;dx=0
\end{equation*}
If $\alpha\neq\beta$, the terms inside parenthesis are not equal to zero.
Hence,
\begin{equation*}
    \int_{0}^{1}xJ_p(\alpha)J_p(\beta)\;dx=0
\end{equation*}
If $\alpha\neq\beta$, the terms inside parenthesis are not equal to zero.
Hence, we can simply divide both side by it and the integral is not zero.
To find its value, suppose that $\beta$ is not a zero, unlike $\alpha$.
We can write
\begin{equation*}
    \int_{0}^{1}xJ_p(\alpha)J_p(\beta)\;dx=\frac{\alpha J_p(\beta)J_p(\alpha)}{\beta^2-\alpha^2}
\end{equation*}
Now we let $\beta\rightarrow\alpha$ and evaluate the right term using  L'Hôpital's rule to find
\begin{equation*}
    \lim_{\beta\rightarrow\alpha}\frac{\alpha J_p(\beta)J_p'(\alpha)}{\beta^2-\alpha^2} =\lim_{\beta\rightarrow\alpha}\frac{\alpha J_p'(\beta)J_p'(\alpha)}{2\beta}=\frac{1}{2}J_p'(\alpha)
\end{equation*}


\subsubsection{Hankel's function.} If the first and the second kind of Bessel function are analog to sin and cos, the Hankel's function is an analog to $\exp(\pm ix)=\cos x \pm i\sin x$.
The function is defined as
\begin{align*}
    H_p^{(1)}(x) & =J_p(x)+iN_p(x) \\
    H_p^{(2)}(x) & =J_p(x)-iN_p(x)
\end{align*}

\subsubsection{Hyperbolic Bessel functions.} This function is the solution of
\begin{equation*}
    x^2y''+xy'-(x^2+p^2)y=0
\end{equation*}
and defined as
\begin{align*}
    I_p    & =i^{-p}J_p(ix)                     \\
    K_p(x) & =\frac{\pi}{2}i^{p+1}H_p^{(1)}(ix)
\end{align*}
They are analog to $\sinh x= -i\sin (ix)$ and $\cosh x=\cos (ix)$ respectively.

\subsubsection{Spherical Bessel functions.} If $p$ is a half integer
then the Bessel function $Z_p(x)$ is defined to be spherical Bessel function and defined as follows
\begin{align*}
    j_n(x)       & =\sqrt{\frac{\pi}{2x}}J_{n+1/2}(x)=\left(-\frac{d}{dx}\right)^n\left(\frac{\sin x}{x}\right) \\
    y_n(x)       & =\sqrt{\frac{\pi}{2x}}Y_{n+1/2}(x)=\left(\frac{d}{dx}\right)^n\left(\frac{\cos x}{x}\right)  \\
    h_n^{(1)}(x) & =j_n(x)+iy_n(x)                                                                              \\
    h_n^{(2)}(x) & =j_n(x)-iy_n(x)
\end{align*}
From this we can obtain
\begin{equation*}
    J_{1/2}(x)=\frac{2}{\pi x}\sin x, \quad J_{-1/2}(x)=\frac{2}{\pi x}\cos x
\end{equation*}

\subsection{Legendre Function}
The Legendre differential equation
\begin{equation*}
    (1-x^2)y''-2xy'+l(l+1)y=0
\end{equation*}
has the solution of Legendre polynomial, which by the Rodrigues formula is
\begin{equation*}
    P_l(x)=\frac{1}{2^ll!}\frac{d^l}{dx^l}(x^2-1)^l
\end{equation*}
The Legendre polynomial is defined such that $y(1)=P_l(1)=1$.

Another closely related equation is
\begin{equation*}
    (1-x^2)y''-2xy'+\left[l(l+1)-\frac{m^2}{1-x^2}\right]y =0
\end{equation*}
or by substituting $x=\cos\theta$
\begin{equation*}
    \frac{d^2\Phi}{d\theta^2} +\frac{\cos \theta}{\sin\theta}\frac{d\Theta}{d\theta} +\left[l(l+1)-\frac{m^2}{\sin^2\theta}\Theta \right]\Theta =0
\end{equation*}
The solution of said function is the associated Legendre function, which defined by the Rodrigues formula as
\begin{equation*}
    P_l^m(x)=(1-x^2)^{m/2}\left(\frac{d}{dx}\right)^{m}P_l(x)
\end{equation*}
or
\begin{equation*}
    P_l^m(x)=\frac{1}{2^ll!}(1-x^2)^{m/2}\left(\frac{d}{dx}\right)^{l+m}(x^2-1)^l
\end{equation*}
For negative value of $m$, we have
\begin{equation*}
    P_l^{-m}(x)=(-1)^m\frac{(l-m)!}{(l+m)!}P_l^m(x)
\end{equation*}
Negative value of $m$ has the same polynomial order with the positive one, they only differ in constant.
Whereas for negative $x$
\begin{equation*}
    P_l^{-m}(-x)=(-1)^{l+m}P_l^m(x)
\end{equation*}


\subsubsection{Laplace integral representation.} The integral representation for the Legendre polynomial is
\begin{equation*}
    P_l(x)=\frac{1}{\pi}\int_{0}^{\pi}\left(x+\sqrt{x^2-1}\cos\theta\right)^l\;d\theta
\end{equation*}
where the domain is $|x|>1$ due to the square root term.

\subsubsection{Series derivation.} By assuming the solution has the form of power series, we can use the Frobenius method.
We also assume that $s=0$ for simplification.
Thus, each term can be represented as power series
\begin{center}
    \begin{tabular}{r c l c}
        \toprule
                  &     &                                                     & $x^n$               \\
        \midrule
        $y''$     & $=$ & $\displaystyle\sum_{n=0}^{\infty} n(n-1)a_nx^{n-2}$ & $(n+2)(n+1)a_{n+2}$ \\
        $-x^2y''$ & $=$ & $\displaystyle\sum_{n=0}^{\infty} n(n-1)a_nx^{n}$   & $-n(n-1)a_n$        \\
        $-2xy'$   & $=$ & $\displaystyle\sum_{n=0}^{\infty} na_nx^{n}$        & $-na_n$             \\
        $l(l+1)y$ & $=$ & $\displaystyle\sum_{n=0}^{\infty} l(l+1)a_nx^{n}$   & $l(l+1)a_n$         \\
        \bottomrule
    \end{tabular}
\end{center}
From the $x^n$ coefficient
\begin{equation*}
    (n+2)(n+1)a_{n+2}=-a_n[-n(n-1)-n+l(l+1)]
\end{equation*}
We write the coefficient of the $a_s$ as follows
\begin{multline*}
    -n(n-1)-n+l(l+1)=-n^2-2n+l^2+l=l^2-n^2+l-n\\
    =(l+n)(l-n)+l-n=(l-n)(l+n+1)
\end{multline*}
The formula for $n+2$ term is then
\begin{equation*}
    a_{n+2}=-\frac{(l-n)(l+n+1)}{(n+2)(n+1)}a_n
\end{equation*}
Here we have few terms
\begin{align*}
    a_2 & =-\frac{l(l+1)}{2!}a_0                                             \\
    a_3 & =-\frac{(l-1)(l+2)}{3!}a_1                                         \\
    a_4 & =-\frac{(l-2)(l+3)}{4\cdot3}a_2=\frac{l(l+1)(l-2)(l+3)}{4!}a_0     \\
    a_5 & =-\frac{(l-3)(l+4)}{5\cdot4}a_3=\frac{(l-1)(l+2)(l-3)(l+4)}{5!}a_1
\end{align*}
Since neither $a_0$ and $a_1$ not zero, the solution is a superposition of two series in terms of $a_0$ and $a_1$
\begin{multline*}
    y=a_0\left[1-\frac{l(l+1)}{2!}x^2+\frac{l(l+1)(l-2)(l+3)}{4!}x^4-\dots\right]\\
    +a_1\left[x-\frac{(l-1)(l+2)}{3!}x^3+\frac{(l-1)(l+2)(l-3)(l+4)}{5!}x^5-\dots\right]
\end{multline*}

Now consider $l=0$.
The solution takes the form
\begin{equation*}
    y=a_0+a_1\left[x-\frac{1}{3}x^3+\frac{1}{5}x^5-\dots\right]
\end{equation*}
At $x^2=1$ the $a_1$ series is divergent by the integral test
\begin{equation*}
    \int^\infty \frac{1}{2n+1}\;dn=\frac{1}{2}\ln (2n+1)\bigg|^{\infty}=\infty
\end{equation*}
Therefore we throw the $a_1$ series out.
By the definition of Legendre polynomial we have $a_0=1$, thus $P_0(x)=1$.
In simple terms, we cans say that for odd value of $l$, we throw the even value of constant $a_0$; and for even value of $l$, we throw away the odd value of constant $a_1$.

We can use this method to determine the value of $P_l(x)$ for other $l$, but this method is simply terrible to use.
There are other method that are more efficient, Rodrigues formula for example.

\subsubsection{Rodrigues formula proof.} Consider the function $v=(x^2-1)^l$.
Differentiate it with respect to $x$
\begin{equation*}
    \frac{dv}{dx}=l(x^2-1)^{l-1}2x
\end{equation*}
Multiply it with $(x^2-1)$
\begin{equation*}
    (x^2-1)\frac{dv}{dx}=2lxv
\end{equation*}
Differentiate $l+1$ times, which according to the Leibniz’ rule for differentiation
\begin{align*}
    \frac{d^{l+1}}{dx^{l+1}}fg & =\sum_{k=0}^{l+1}\frac{(l+1)!}{k!(l+1-k)!}\left(\frac{d}{dx}\right)^{l+1-k}f\left(\frac{d}{dx}\right)^{k}g                         \\
                               & =\left(\frac{d}{dx}\right)^{l+1}f\left(\frac{d}{dx}\right)^{0}g+ (l+1)\left(\frac{d}{dx}\right)^{l}f\left(\frac{d}{dx}\right)^{1}g \\
                               & \qquad+\frac{l(l+1)}{2}\left(\frac{d}{dx}\right)^{l-1}f\left(\frac{d}{dx}\right)^{2}g+\dots
\end{align*}
For the left side, we take $f=dv/dx$ and $g=(x^2-1)$
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}\left[\frac{dv}{dx}(x^2-1)\right]= (x^2-1)\frac{d^{l+2}v}{dx^{l+2}}+2(l+1)x\frac{d^{l+1}v}{dx^{l+1}}+\frac{2l(l+1)}{2!}\frac{d^{l}v}{dx^{l}}
\end{equation*}
As for the right side, we take $f=v$ and $g=x$
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}\left[2lvx\right]=2lx\frac{d^{l+1}v}{dx^{l+1}} +2l(l+1)\frac{d^{l}v}{dx^{l}}
\end{equation*}
Equating both side
\begin{align*}
    (1-x^2)\frac{d^{l+2}v}{dx^{l+2}} +\left[2xl-2x(l+1)\right]\frac{d^{l+1}v}{dx^{l+1}} +\left[2l(l+1)-l(l+1)\right]\frac{d^{l}v}{dx^{l}} & =0 \\
    (1-x^2)\left(\frac{d^lv}{dx^l}\right)' -2x\left(\frac{d^lv}{dx^l}\right)' +l(l+1)\frac{dv}{dx}                                        & =0
\end{align*}
This is the Legendre's equation if
\begin{equation*}
    y=\frac{d^lv}{dx^l}=\frac{d^l}{dx^l} (x^2-1)^l
\end{equation*}

The next step is to apply the definition of Legendre polynomial $P_l(1)=1$.
This can be achieved by determining the value of constant $C$ such that
\begin{equation*}
    y(1)=C\frac{d^l}{dx^l} (x^2-1)^l\bigg|_{x=1}=1
\end{equation*}
We use the relation
\begin{equation*}
    \frac{d^l}{dx^l}(x^2-1)^l\bigg|_{x=1}=2^ll!
\end{equation*}
which can be proofed by the induction method.
First, consider the base case of $l=0$.
According to the hypothesis,
\begin{align*}
    \frac{d^0}{dx^0}(x^2-1)^0\bigg|_{x=1} & =2^00! \\
    1                                     & =1
\end{align*}
Then consider the inductive case $l+1$
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1}\bigg|_{x=1}=2^{l+1}(l+1)!
\end{equation*}
By the Leibniz' rule, we set $f=(x^2-1)^l$ and $g=(x^2-1)$
\begin{multline*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1} =(x^2-1)\frac{d^{l+1}}{dx^{l+1}}(x^2-1)^l +2(l+1)x\frac{d^{l}}{dx^{l}}(x^2-1)^l \\
    +\frac{2l(l+1)}{2!}\frac{d^{l-1}}{dx^{l-1}}(x^2-1)^l
\end{multline*}
On evaluating it at $x=1$, we have the first and the third term to be zero.
The first one is obvious enough; but for the third term, note that the term $(x^2-1)$ will survive, thus evaluating at $x=1$ will result in said term to be zero also.
All that remain is the second term
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1}\bigg|_{x=1}=2(l+1)x\frac{d^{l}}{dx^{l}}(x^2-1)^l
\end{equation*}
By using the hypothesis, we have completed our proof
\begin{equation*}
    \frac{d^{l+1}}{dx^{l+1}}(x^2-1)^{l+1}\bigg|_{x=1}=2(l+1)x2^ll!=2^{l+1}(l+1)!
\end{equation*}
Since the relation have been proofed, we can use it to obtain
\begin{equation*}
    C\frac{d^l}{dx^l} (x^2-1)^l\bigg|_{x=1}=1\implies C=\frac{1}{2^ll!}
\end{equation*}
Thus
\begin{equation*}
    y(x)=P_l(x)=\frac{1}{2^ll!}\frac{d^l}{dx^l} (x^2-1)^l
\end{equation*}

We begin the proof of the Rodrigues formula for associated Legendre polynomial by substituting
\begin{equation*}
    y=(1-x^2)^{\frac{m}{2}}u
\end{equation*}
Now we evaluate the first derivative
\begin{align*}
    y' & =u\frac{m}{2}(1-x^2)^{\frac{m}{2}-1}(-2x)+ (1-x^2)^{\frac{m}{2}}u' \\
    y' & =(1-x^2)^{\frac{m}{2}}u'-mx(1-x^2)^{\frac{m}{2}-1}u
\end{align*}
Then the second
\begin{align*}
    y'' & =(1-x^2)^{\frac{m}{2}}u''-mx(1-x^2)^{\frac{m}{2}-1}u' -mx(1-x^2)^{\frac{m}{2}-1}u'                    \\
        & \quad-mu\left[(1-x^2)^{\frac{m}{2}-1} +x\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-2}(-2x)\right] \\
    y'' & =(1-x^2)^{\frac{m}{2}}u''-2mx(1-x^2)^{\frac{m}{2}-1}u'                                                \\
        & \quad-m\left[(1-x^2)^{\frac{m}{2}-1} -2x^2\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-2}\right]u
\end{align*}
Now consider the equation that we are going to solve
\begin{equation*}
    (1-x^2)y''-2xy'+\left[l(l+1)-\frac{m^2}{1-x^2}\right]y =0
\end{equation*}
On using the substituted value of $y$ and its derivatives, we can write the first term as
\begin{align*}
    (1-x^2)y'' & =(1-x^2)^{\frac{m}{2}+1}u''-2mx(1-x^2)^{\frac{m}{2}}u'                                            \\
               & \quad-m\left[(1-x^2)^{\frac{m}{2}} -2x^2\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-1}\right]u
\end{align*}
then the second
\begin{equation*}
    -2xy'=2mx^2(1-x^2)^{\frac{m}{2}-1}u -2x(1-x^2)^{\frac{m}{2}}u'
\end{equation*}
and the third
\begin{equation*}
    \left[l(l+1)-\frac{m^2}{1-x^2}\right]y=\left[l(l+1)(1-x^2)^{\frac{m}{2}}-m^2(1-x^2)^{\frac{m}{2}-1}\right]u
\end{equation*}
Hence we have
\begin{gather*}
    (1-x^2)^{\frac{m}{2}+1}u''-2(m+1)x(1-x^2)^{\frac{m}{2}}u' \\
    +\bigg[l(l+1)(1-x^2)^{\frac{m}{2}}-m^2(1-x^2)^{\frac{m}{2}-1}\\
        +2mx^2(1-x^2)^{\frac{m}{2}-1} \\
        -m(1-x^2)^{\frac{m}{2}} +2mx^2\left(\frac{m}{2}-1\right)(1-x^2)^{\frac{m}{2}-1}\bigg]u=0
\end{gather*}
Terms inside square bracket can be simplified into
\begin{equation*}
    l(l+1)(1-x^2)^{\frac{m}{2}}-m^2(1-x^2)^{\frac{m}{2}-1} -m(1-x^2)^{\frac{m}{2}} +m^2x^2(1-x^2)^{\frac{m}{2}-1}
\end{equation*}
Then
\begin{equation*}
    l(l+1)(1-x^2)^{\frac{m}{2}}-m(1-x^2)^{\frac{m}{2}} -m^2(1-x^2)(1-x^2)^{\frac{m}{2}-1}
\end{equation*}
Finally
\begin{equation*}
    l(l+1)(1-x^2)^{\frac{m}{2}} -m(m+1)(1-x^2)^{\frac{m}{2}}
\end{equation*}
Substituting back and multiplying by $(1-x^2)^2/m$
\begin{equation*}
    (1-x^2)u''-2(m+1)xu'+\left[l(l+1)-m(m+1)\right]u=0
\end{equation*}
Now the associated Legendre equation turns into the Legendre equation if $m=0$ and has solution of $u=P_l$ or $(1-x^2)^{\frac{m}{2}}P_l$,  the solution is.
For the case of general integer $m$, first differentiate it, to obtain
\begin{gather*}
    -2xu'' +(1-x^2)u'''-2(m+1)(u'+xu'')\\
    +\left[l(l+1)-m(m+1)\right]u'=0
\end{gather*}
Or
\begin{gather*}
    (1-x^2)(u')''-[2(m+1)+2]x(u')'\\
    +\left[l(l+1)-m(m+1)-2(m+1)\right]u'=0
\end{gather*}
This just the previous Legendre equation with $u\rightarrow u'$ and $m\rightarrow m+1$.
If $u=P_l$ is the solution at $m=0$ and $u=P_l'$ is the solution at $m+1$, then by the induction method we can say that for integer $0\leq m\leq l$, $u=(P_l)^{(m)}$ is the solution.
To put it in other words, the solution of associated Legendre equation is
\begin{align*}
    y & =(1-x^2)^{\frac{m}{2}}\left(\frac{d}{dx}\right)^m P_l                         \\
    y & =\frac{1}{2^ll!}(1-x^2)^{\frac{m}{2}}\left(\frac{d}{dx}\right)^{l+m}(x^2-1)^l
\end{align*}


\subsubsection{Generating function.} The function $\Phi(x,h)$ below is the generating function for the Legendre polynomial
\begin{equation*}
    (1-2xh+h^2)^{-1/2}=\sum_{l=0}^{\infty}h^lP_l(x)
\end{equation*}

\paragraph*{Proof.} We first show that  the function indeed can be expressed as series.
For brevity, we take $u=2xh-h^2$
\begin{align*}
    (1-u)^{-1/2} & =\sum_{k=0}^{\infty}\frac{\Gamma(1/2)(-u)^k}{\Gamma(k+1)\Gamma(1/2-k)} \\
                 & =1+\frac{1}{2}u+\frac{(-1/2)(-3/2)}{\Gamma(3)}u^{2}+\dots              \\
                 & =1+\frac{1}{2}(2xh-h^2)+\frac{3}{8}(4x^2-4xh^3+h^2)+\dots              \\
                 & =1+ xh +\left(\frac{3}{2}x^2-\frac{1}{2}\right)h^2+\dots               \\
    \Phi(x,h)    & =P_0(x) +hP_1(x) +h^2P_2(x) +\dots
\end{align*}
By evaluating the series at $x=1$, we have the expression in terms of $h$
\begin{equation*}
    \Phi(1,h)=P_0(1) +hP_1(1) +h^2P_2(1) +\dots
\end{equation*}
thus, the function does indeed have the identity $P_l(1)=1$.
Next we will show that the generating function satisfies the Legendre equation by the following formula
\begin{equation*}
    (1-x^2)\frac{\partial^2\Phi}{\partial x^2}-2x\frac{\partial\Phi}{\partial x}+h\frac{\partial^2h\Phi}{\partial h^2}=0
\end{equation*}
Substituting the series representation of the generating function
\begin{equation*}
    (1-x^2)\sum_{l=0}^{\infty}h^lP''_l(x) -2x\sum_{l=0}^{\infty}h^lP'_l(x) +\sum_{l=0}^{\infty}(l+1)lh^lP_l(x)=0
\end{equation*}
Taking the coefficient of $h^l$, we obtain the Legendre function
\begin{equation*}
    (1-x^2)P''_l(x) -2xP'_l(x) +l(l+1)P_l(x)=0
\end{equation*}

\subsubsection{Recursion relations.} Some examples of recursion
relations areas follows.
\begin{gather*}
    lP_l(x)=(2l-l)xP_{l-1}(x)-l(-1)P_{l-2}(x)\\
    xP_l'-P_{l-1}'=lP_l(x)\\
    P_l'(x)xP_{l-1}'=lP_{l-1}(x)\\
    (1-x^2)P_l'(x)=lP_{l-1}(x)lxP_l(x)\\
    (2l+1)P_l(x)=P_{l+1}'(x)-P_{l-1}'{x}\\
    (1-x^2)P_{l-1}'(x=lxP_{l-1})(x)-lP_{l}(x)
\end{gather*}
Also some identity
\begin{equation*}
    P_l(-x)=(-1)^lP_l(x)
\end{equation*}

\paragraph*{First relation proof.} Differentiate the generating function with respect to $h$
\begin{equation*}
    \frac{\partial \Phi}{\partial h}=-\frac{1}{2}(1-2xh+h^2)^{-3/2}(-2x+2h)
\end{equation*}
Or
\begin{equation*}
    (1-2xh+h^2)\frac{\partial \Phi}{\partial h}=(x-h)\Phi
\end{equation*}
First write it as power series
\begin{equation*}
    (1-2xh+h^2)\sum_{l=0}^{\infty}lh^{l-1}P_l(x)=(x-h)\sum_{l=0}^{\infty}h^lP_l
\end{equation*}
then take the $h^{l-1}$ coefficient
\begin{equation*}
    lP_l-2x(l-1)P_{l-1}+(l-2)P_{l-2}=xP_{l-1}-P_{l-2}
\end{equation*}
Rearrange it
\begin{align*}
    lP_l & =\left[2x(l-1)+x\right]P_{l-1} -\left[l-2+1\right]P_{l-2} \\
    lP_l & =(2l-l)xP_{l-1}(x)-l(-1)P_{l-2}(x)
\end{align*}

\paragraph*{Second relation proof.} 404.

\paragraph*{Third relation proof.} 404.

\paragraph*{Fourth relation proof.} 404.

\paragraph*{Fifth relation proof.} 404.

\paragraph*{Sixth relation proof.} 404.

\paragraph*{Bonus.} Consider the case of negative value $x$ and $t$ for the $\Phi(x,t)$.
Substituting it to the function representation
\begin{equation*}
    \Phi(-x,-t)=(1-2(-x)(-h)+(-h)^2)^{-1/2} =(1-2xh+h^2)^{-1/2}
\end{equation*}
We see that this is simply $\Phi(x,t)=\sum h^lP_l(x)$.
Now, substituting it to the series representation
\begin{equation*}
    \Phi(-x,-t)=\sum_{l=0}^{\infty}(-h)^lP_l(-x)=\sum_{l=0}^{\infty}(-1)^lh^lP_l(-x)
\end{equation*}
Now taking the coefficient of $h^l$
\begin{equation*}
    (-1)^lP_l(-x)=P_l(x)\implies P_l(-x)=(-1)^lP_l(x)
\end{equation*}

\subsubsection{Orthogonality.} The following equation state the orthogonality of Legendre polynomial on $(-1,1)$
\begin{equation*}
    \int_{-1}^{1}P_l(x)P_m(x)\;dx=\frac{2}{2l+1}\delta_{lm}
\end{equation*}
On using this, we also obtain the following theorem.
\begin{equation*}
    \int_{-1}^{1}P_l(x)\cdot(\text{polynomial degree }l<0)\;dx=0
\end{equation*}

For the case of associated Legendre polynomial, we have
\begin{equation*}
    \int_{-1}^{1}[P_l^m(x)]^2\;dx=\frac{2}{2l+1}\frac{(l+m)!}{(l-m)!}
\end{equation*}

\paragraph*{Proof.} Consider two Legendre polynomials for two different value of $l$
\begin{align*}
    \frac{d}{dx}\left[(1-x^2)P_l'\right] +l(l+1) P_l & =0 \\
    \frac{d}{dx}\left[(1-x^2)P_m'\right] +l(l+1) P_m & =0
\end{align*}
Multiply the first equation with $P_m$ and the second with $P_l$
\begin{align*}
    P_m\frac{d}{dx}\left[(1-x^2)P_l'\right] +l(l+1) P_lP_m & =0 \\
    P_l\frac{d}{dx}\left[(1-x^2)P_m'\right] +m(m+1) P_lP_m & =0
\end{align*}
Subtract both
\begin{multline*}
    P_m\frac{d}{dx}\left[(1-x^2)P_l'\right]
    -P_l\frac{d}{dx}\left[(1-x^2)P_m'\right]\\
    +\left[(l(l+1))-m(m+1)\right]P_lP_m
\end{multline*}
The first two terms can be written as
\begin{align*}
    \frac{d}{dx}\left[(1-x^2)(P_mP_l'-P_lP_m')\right] & = \frac{d}{dx}\left[(1-x^2)P_mP_l'-(1-x^2P_lP_m')\right]        \\
                                                      & =(1-x^2)P_l'P_m' +P_m\frac{d}{dx}\left[(1-x^2)P_l'\right]       \\
                                                      & \qquad-(1-x^2)P_l'P_m' -P_l\frac{d}{dx}\left[(1-x^2)P_m'\right]
\end{align*}
which is what those two terms are.
Then integrate between $(-1,1)$
\begin{multline*}
    \int_{-1}^{1}\frac{d}{dx}\left[(1-x^2)(P_mP_l'-P_lP_m')\right]\;dx \\
    +\int_{-1}^{1} \left[(l(l+1))-m(m+1)\right]P_lP_m\;dx=0
\end{multline*}
Evaluate it
\begin{equation*}
    (1-x^2)(P_mP_l'-P_lP_m')\bigg|_{-1}^{1} +\left[(l(l+1))-m(m+1)\right]\int_{-1}^{1} P_lP_m \; dx=0
\end{equation*}
The first term is zero due to the term of $(1-x^2)$; while the second term is also zero if $m=l$, which due to the constant term outside integral.
Hence, it is proved that for $m=l$, the following integral is true
\begin{equation*}
    \int_{-1}^{1} P_lP_m \; dx=0
\end{equation*}
By considering $P_m$ as a polynomial order $m$, we can also state
\begin{equation*}
    \int_{-1}^{1} P_l\cdot(\text{polynomial degree }l<0)\; dx=0
\end{equation*}

To prove the value of the integral for the same order $l$, first recall the recursive relation of
\begin{equation*}
    lP_l=xP_l'-P_{l-1}'
\end{equation*}
Multiply by $P_l$ and integrate on $(-1,1)$
\begin{equation*}
    l\int_{-1}^{1}[P_l]^2\;dx=\int_{-1}^{1}xP_lP_l'\;dx -\int_{-1}^{1}P_lP_{l-1}'\;dx
\end{equation*}
The second term is zero since $P_{l-1}'$ is a polynomial order $l-2$.
We evaluate the remaining integral using integration by part
\begin{equation*}
    \int_{-1}^{1}xP_lP_l'\;dx =x[P_l]^2\bigg|_{-1}^{1}-\int_{-1}^{1}P_l\frac{d}{dx}\left[xP_l\right]\;dx
\end{equation*}
Recalling the $[P_l(-1)]^2=(-1)^{2l}=1$ and using the derivative product rule for the second integral
\begin{align*}
    \int_{-1}^{1}xP_lP_l'\;dx & =2-\int_{-1}^{1}[P_l]^2\;dx -\int_{-1}^{1}xP_lP_l'\;dx \\
    \int_{-1}^{1}xP_lP_l'\;dx & =1-\frac{1}{2}\int_{-1}^{1}[P_l]^2\;dx
\end{align*}
Then substituting back into our original equation
\begin{align*}
    l\int_{-1}^{1}[P_l]^2\;dx=1-\frac{1}{2}\int_{-1}^{1}[P_l]^2\;dx \\
    \int_{-1}^{1}[P_l]^2\;dx=\frac{1}{l+1/2}=\frac{2}{2l+1}
\end{align*}
Or by using Kronecker delta, we can also express the result as
\begin{equation*}
    \int_{-1}^{1}P_lP_m\;dx=\frac{2}{2l+1}\delta_{lm}
\end{equation*}

\subsubsection{Another form of associated Legendre equation.} We shall prove
\begin{equation*}
    \frac{d^2y}{d\theta^2} +\frac{\cos \theta}{\sin\theta}\frac{dy}{d\theta} +\left[l(l+1)-\frac{m^2}{\sin^2\theta} \right]y =0
\end{equation*}
is the associated Legendre equation by substituting $x=\cos\theta$.
First we evaluate the differential
\begin{equation*}
    \frac{dy}{d\theta}=\frac{dy}{dx}\frac{dx}{d\theta}=-\sin\theta\frac{dy}{dx}=-(1-x^2)^{1/2}\frac{dy}{dx}
\end{equation*}
Applying the operator one more
\begin{align*}
    \frac{d^2y}{d\theta^2} & =-(1-x^2)^{1/2}\frac{d}{dx}\left[-(1-x^2)^{1/2}\frac{dy}{dx}\right]                              \\
                           & =-(1-x^2)^{1/2}\left[\frac{x}{(1-x^2)^{1/2}}\frac{dy}{dx} -(1-x^2)^{1/2}\frac{d^2y}{dx^2}\right] \\
    \frac{d^2y}{d\theta^2} & =(1-x^2)^{1/2}\frac{d^2y}{dx^2}-x\frac{dy}{dx}
\end{align*}
Then we simply substituted both into the another form of the associated Legendre equation
\begin{align*}
    (1-x^2)^{1/2}\frac{d^2y}{dx^2}-2x\frac{dy}{dx}+\left[l(l+1)-\frac{m^2}{(1-x^2)^{1/2}} \right]y=0
\end{align*}

\subsection{Hermite Function}
The diﬀerential equation
\begin{equation*}
    y_n''-x^2y_n=-(2n+1)y_n
\end{equation*}
has the solution called the Hermite function
\begin{equation*}
    y_n=e^{x^2/2}\left(\frac{d}{dx}\right)^ne^{-x^2}
\end{equation*}

Another closely related equation is called the Hermite equation
\begin{equation*}
    y''-2xy'+2ny=0
\end{equation*}
which is solved by the Hermite polynomial
\begin{equation*}
    H_n(x)=(-1)^ne^{x^2}\left(\frac{d}{dx}\right)^ne^{-x^2}
\end{equation*}
Hermite polynomial can also be obtained by multiplying the Hermite function by $(-1)^ne^{x^2/2}$.
This multiplication is performed such that the polynomial is raising from negative $-\infty$ and orthogonal on $(-\infty,\infty)$.

The generating function $\phi(x,h)$ for Hermite polynomial is
\begin{equation*}
    \exp(2xh-h^2)=\sum_{n=0}^{\infty}H_n(x)\frac{h^n}{n!}
\end{equation*}
Using the generating function we obtain the following recursion relation
\begin{gather*}
    H_n'(x)=2xH_{n-1}(x)\\
    H_{n+1}(x)=2xH_{n}(x)-2nH_{n-1}(x)
\end{gather*}

\subsubsection{Derivation.} Using the operator $D$, we have
\begin{align*}
    (D-x)(D+x)y & =(D-x)(Dy+xy)        \\
                & =D^2y+y+xDy-xDy-x^2y \\
                & =D^2-x^2y_n+y        \\
\end{align*}
and
\begin{align*}
    (D+x)(D-x)y & =(D-x)(Dy-xy)        \\
                & =D^2y-y-xDy+xDy-x^2y \\
                & =D^2-x^2y_n-y
\end{align*}
Then, we can write
\begin{gather*}
    (D-x)(D+x)y_n=D^2-x^2y_n+y_n=-2ny_n\\
    (D+x)(D-x)y_n=D^2-x^2y_n-y_n=-2(n+1)y_n
\end{gather*}
Operating $(D+x)$ on the first equation and $(D-x)$ on the second
\begin{align*}
    (D+x)(D-x)(D+x)y_n=-2n(D+x)y_m \\
    (D-x)(D+x)(D-x)y_n=-2(n+1)(D-x)y_n
\end{align*}
If the equations are identical, that is $y_n=(D-x)y_m$ and $n+m+1$ for the first $n$ equation and second $m$ equations
\begin{align*}
    -2ny_n  & =-2(m+1)y_m \\
    y_{m+1} & =(D-x)y_m
\end{align*}
If $y_n=(D=x)y_m$ and $n+1=m$ for the second $n$ equations and the first $m$ equations
\begin{align*}
    -2(n+1)y_n & =-2m(D+x)y_m \\
    y_{m-1}    & =(D+x)y_m
\end{align*}
Mathematically, these operators are called the raising operator $(D-x)$ and lowering operator $(D+x)$.
Quantum mechanics definition of raising operator $a^\dagger$ and lowering operator $a$ is different to accommodate adjoint $[a,a^\dagger]=1$
\begin{align*}
    a^\dagger & =\frac{1}{\sqrt{2}}(x-D) \\
    a         & =\frac{1}{\sqrt{2}}(x+D)
\end{align*}

We can derive the solution for Hermite equations
\begin{equation*}
    y''-2xy'+2ny=0
\end{equation*}
using the Rodrigues formula. First, the integral factor is evaluated as follows
\begin{equation*}
    \mu=\exp\left(\int_{0}^{x}-2x\;dx\right)=e^{-x^2}
\end{equation*}
The solution is the
\begin{equation*}
    y=\frac{1}{e^{-x^2}}\left(\frac{d}{dx}\right)^ne^{-x^2}
\end{equation*}
The Hermite polynomial is obtained by multiplying the solution with factor of $(-1)^n$
\begin{equation*}
    H_n=(-1)^ne^{x^2}\left(\frac{d}{dx}\right)^ne^{-x^2}
\end{equation*}

\subsubsection{Orthogonality.} We state the orthogonality of Hermite function or Hermite polynomial as follows.
\begin{equation*}
    \int_{-\infty}^{\infty}e^{-x^2}H_n(x)H_m(x)\;dx=\sqrt{\pi}2^n n!\delta_{nm}
\end{equation*}
The Hermite polynomial is orthogonal on $(-\infty,\infty)$ with respect to weight function $e^{-x^2}$.
This is why the Hermite function is defined in such way to allow the function to be orthogonal on $(-\infty,\infty)$ with respect to itself
\begin{equation*}
    \int_{-\infty}^{\infty}y_ny_m\;dx=\sqrt{\pi}2^nn!\delta_{nm}
\end{equation*}

\subsubsection{Recursive relation derivation.}
Derivation the generating function
\begin{equation*}
    \exp(2xh-h^2)=\sum_{n=0}^{\infty}H_n(x)\frac{h^n}{n!}
\end{equation*}
with respect either $x$ or $h$ will result in the recursive relation.
The first relation is obtained by performing derivative to the $\phi(x,h)$ with respect to $x$
\begin{align*}
    2h\exp(2xh-h^2)                & =\sum H_n'\frac{h^n}{n!} \\
    2\sum\frac{H_{n-1}}{(n-1)!}h^n & =\sum \frac{H_n'}{n!}h^n
\end{align*}
and equating the $h^n$ term
\begin{align*}
    2\frac{H_{n-1}}{(n-1)!} & =\frac{H_n'}{n!} \\
    2nH_{n-1}               & =H_n'
\end{align*}
In other hand, the second relation is obtained by derivating with respect to $h$
\begin{align*}
    (2x-2h)\exp(2xh-h^2)                                      & =\sum\frac{nH_n}{n!}h^{n-1} \\
    2x\sum \frac{H_n}{n!}h^n-2 \sum \frac{H_{n-1}}{(n-1)!}h^n & =\sum \frac{H_(n+1)}{n!}
\end{align*}
and, as before, equation the $h^n$ terms
\begin{align*}
    2x\frac{H_n}{n!}-2\frac{H_{n-1}}{(n-1)!} & =\frac{H_{n+1}}{n!} \\
    2xH_n-2nH_{n-1}                          & =H_{n+1}
\end{align*}

\subsection{Laguerre function}
The differential equation
\begin{equation*}
    xy''+(1-x)y'+ny=0
\end{equation*}
has the solution of Laguerre polynomials
\begin{equation*}
    L_n(x)=\frac{1}{n!}e^x\left(\frac{d}{dx}\right)^n(x^ne^{-x})
\end{equation*}
or if we were to carry the differentiation using Leibniz's rule
\begin{equation*}
    L_n(x)=\sum_{m=0}^{n}(-1)^m\binom{n}{m}\frac{x^m}{m!}
\end{equation*}

Another closely related equation is
\begin{equation*}
    xy''+(k+1-x)y'+ny=0
\end{equation*}
which is solved by the associated Laguerre polynomials
\begin{equation*}
    L_n^k(x)=(-1)^k\left(\frac{d}{dx}\right)^kL_{n+k}(x)
\end{equation*}

\subsubsection{Derivation.}
The Laguerre equation
\begin{equation*}
    xy''+(1-x)y'+ny=0
\end{equation*}
can be solved using Rodrigues formula, where the integral factor is
\begin{equation*}
    \mu=\frac{1}{x}\exp\left(\int_{0}^{x}\frac{1-x}{x}\;dx\right)=\frac{\exp(\ln x-x )}{x}=e^{-x}
\end{equation*}
The solution then reads
\begin{equation*}
    y=\frac{1}{e^{-x}}\left(\frac{d}{dx}\right)^n\left(x^ne^{-x}\right)
\end{equation*}
On multiplying with $1/n!$ we obtain the Laguerre polynomials
\begin{equation*}
    L_n(x)=\frac{1}{n!}e^x\left(\frac{d}{dx}\right)^n(x^ne^{-x})
\end{equation*}

\subsubsection{Recursive relation.}
The Laguerre polynomials satisfy the recurrence relation
\begin{equation*}
    (n+1)L_{n+1}(x) = (2n+1 - x)L_n(x) - nL_{n-1}(x),
\end{equation*}
with initial conditions
\begin{equation*}
    L_0(x) = 1, \qquad L_1(x) = 1 - x.
\end{equation*}

For the associated Laguerre polynomials $L_n^k(x)$, the recurrence relation generalizes to
\begin{equation*}
    (n+1)L_{n+1}^k(x) = \big(2n+1+\alpha - x\big)L_n^k(x) - (n+\alpha)L_{n-1}^k(x).
\end{equation*}


\subsection{Laplace's Equation}
Consider scalar function $u$, which may represent gravitational potential in a region containing no mass, the electrostatic potential in a charge-free region, the steady-state temperature in a region containing no sources of heat, or the velocity potential for an incompressible fluid with no vortices and no sources or sinks.
Laplace's equation state that
\begin{equation*}
    \nabla^2 u=0
\end{equation*}

\subsubsection{Cylindrical domain.} Suppose we evaluate Laplace equation in cylindrical domain.
The Laplacian reads
\begin{equation*}
    \nabla^2u= \frac{1}{r}\frac{\partial}{\partial r}\Biggl(r\frac{\partial u}{\partial r}\Biggr)+\frac{1}{r^2} \frac{\partial^2u}{\partial \phi^2}+ \frac{\partial^2u}{\partial z^2}
\end{equation*}

By the separation of variables, we assume the solution of $u=R(r)\Phi(\phi)Z(z)$.
Thus, the Laplace's equation now reads
\begin{equation*}
    \frac{\Phi R}{r}\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +\frac{RZ}{r^2} \frac{\partial^2\Phi}{\partial \phi^2}
    + R\Phi\frac{\partial^2Z}{\partial z^2}=0
\end{equation*}
Then we divide by $u=R(r)\Phi(\phi)Z(z)$,
\begin{equation*}
    \frac{1}{Rr}\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +\frac{1}{\Phi r^2} \frac{\partial^2\Phi}{\partial \phi^2}
    + \frac{1}{Z}\frac{\partial^2Z}{\partial z^2}=0
\end{equation*}
Since only last term is the function of $z$ alone, we can safely say that it is a constant.
Therefore, we define
\begin{equation*}
    \frac{1}{Z}\frac{\partial^2Z}{\partial z^2}=K^2\implies Z=Ae^{Kz}+Be^{-KZ}
\end{equation*}
Substituting this value and multiplying by $r^2$, we have
\begin{equation*}
    \frac{r}{R}\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +\frac{1}{\Phi } \frac{\partial^2\Phi}{\partial \phi^2}
    +K^2r^2=0
\end{equation*}
Now we see that the second term is constant.
We define
\begin{equation*}
    \frac{1}{\Phi}\frac{\partial^2 \Phi}{\partial \phi}=-n^2\implies \Phi=C\sin n\theta +D\cos n\theta
\end{equation*}
where $n$ is an integer.
The reason for said separation constant is due to periodicity.
For a position in polar coordinate, we denote them as $\theta+2n\pi$.
Hence, for a most physical reason, the position $\theta$ and $\theta+2n\pi$ must give the same result, which is possible if the solution is periodic with period of $2\pi$.
Finally, we substitute this and multiplying with $R$ to obtain the radial solution
\begin{equation*}
    r\frac{\partial}{\partial r}\Biggl(r\frac{\partial R}{\partial r}\Biggr)
    +(K^2r^2-n^2)R=0
\end{equation*}
This is Bessel function, in particular
\begin{equation*}
    R=\sum_{m=0}^{\infty}E_mJ_m(Kr)+\sum_{m=0}^{\infty}F_mN_m(Kr)
\end{equation*}
Now, putting it all together, we have the most general solution for the Laplace's equation in cylindrical domain
\begin{multline*}
    u=\sum_{m=0}^{\infty}\left[A_me^{Kz}+B_me^{-KZ}\right]\left[C_m\sin n\theta +D_m\cos n\theta\right]\\
    \left[E_mJ_m(Kr)+F_mN_m(Kr)\right]
\end{multline*}

\subsubsection{Spherical domain.} The Laplacian reads
\begin{equation*}
    \nabla^2u=\frac{1}{r}\frac{\partial}{\partial r}\left(r^2\frac{\partial u}{\partial r}\right) +\frac{1}{r^2\sin\theta}\frac{\partial}{\partial \theta}\left(\sin\theta \frac{\partial u}{\partial \theta}\right) +\frac{1}{r^2\sin^2\theta}\frac{\partial^2u}{\partial \phi^2}=0
\end{equation*}
We assume the solution of $u = R(r)\Phi(\phi)Z(z)$
\begin{equation*}
    \frac{\Phi Z}{r}\frac{\partial}{\partial r}\left(r^2\frac{\partial R}{\partial r}\right) +\frac{R\Phi}{r^2\sin\theta}\frac{\partial}{\partial \theta}\left(\sin\theta \frac{\partial \Theta}{\partial \theta}\right) +\frac{R\Theta}{r^2\sin^2\theta}\frac{\partial^2\Phi}{\partial \phi^2}=0
\end{equation*}
As before, we multiply it by $u = R(r)\Phi(\phi)Z(z)$
\begin{equation*}
    \frac{1}{R}\frac{d}{dr}\left(r^2\frac{dR}{dr}\right) +\frac{1}{\Theta\sin\theta}\frac{d}{d\theta}\left(\sin\theta\frac{d\Theta}{d\theta}\right) +\frac{1}{\Phi\sin^2\phi}\frac{d^2\Phi}{d\phi^2}=0
\end{equation*}
If we multiply by $\sin^2\theta$, we see that the last terms is a function of $\phi$, while the other two are not.
Hence, we can say
\begin{equation*}
    \frac{1}{\Phi}\frac{d^2\Phi}{2\phi^2}=-m^2\implies\phi=Ae^{im\phi}+ Be^{-im\phi}
\end{equation*}
The constant is chosen to be negative due to periodicity, as before.
With this, we can write
\begin{equation*}
    \frac{1}{R}\frac{d}{dr}\left(r^2\frac{dR}{dr}\right) +\frac{1}{\Theta\sin\theta}\frac{d}{d\theta}\left(\sin\theta\frac{d\Theta}{d\theta}\right) -\frac{m^2}{\sin^2\theta}=0
\end{equation*}
The first term is a Function of $r$ while the other two is a function of $\theta$, so
\begin{gather*}
    \frac{1}{R}\frac{d}{dr}\left(r^2\frac{dR}{dr}\right) =l(l+1)\\
    \frac{1}{\sin\theta}\frac{d}{d\theta}\left(\sin\theta\frac{d\Theta}{d\theta}\right) -\frac{m^2}{\sin^2\theta}\Theta +l(l+1)\Theta =0
\end{gather*}

We first consider the first equation
\begin{equation*}
    r^2\frac{d^2R}{dr^2}+2r\frac{dR}{dr}-l(l+1)R=0
\end{equation*}
By the Euler's method of substituting $r=e^z$, we see that $a_1=2$ and $a_2=1$, thus we write
\begin{equation*}
    R''(e^z)+R'(e^z)-l(l+1)R(e^z)=0\\
\end{equation*}
Using the method of writing differential as operator
\begin{align*}
    [D^2+D-l(l+1)] R(e^z) & =0 \\
    [D+(l+1)][D-l]R(e^z)  & =0
\end{align*}
This has the solution
\begin{equation*}
    R(e^z)= Ae^{lz}+Be^{-l(l+1)z}
\end{equation*}
Substituting back $r=e^z$, we obtain the solution in terms of $r$
\begin{equation*}
    R(r)= Ar^{l}+Br^{-l(l+1)}
\end{equation*}

Next we consider the $\theta$ equation
\begin{equation*}
    \frac{d^2\Phi}{d\theta^2} +\frac{\cos \theta}{\sin\theta}\frac{d\Theta}{d\theta} +\left[l(l+1)-\frac{m^2}{\sin^2\theta} \right]\Theta =0
\end{equation*}
This is the associated Legendre equation if we substitute $x=\cos \theta$.
Thus, we have the solution
\begin{equation*}
    \Theta=P_l^m(\cos\theta)
\end{equation*}

Putting them all together, we have the general solution to the Laplacian
\begin{equation*}
    u=\sum_{l=0}^{\infty}\sum_{m=-l }^{l}\left(A_{lm}r^l +\frac{B_{lm}}{r^{l+1}}\right)Y_l^m(\theta,\phi)
\end{equation*}
where $Y_l^m(\theta,\phi)$ is the spherical harmonics.


\subsection{Poisson’s Equation}
Consider the same scalar function $u$ as the case of Laplace's equation, however we have a region containing mass, electric charge, or sources of heat or fluid denoted by $f(x,y,z)$.
Poisson's equation is written as
\begin{equation*}
    \nabla^2 u=f(x,y,z)
\end{equation*}

\subsection{Heat Flow or Diffusion Equation}
Now suppose that the temperature is non-steady.
The flow of temperature is governed by the equation
\begin{equation*}
    \nabla^2 u=\frac{1}{\alpha}\frac{\partial u}{\partial t}
\end{equation*}
where $\alpha$ is a constant called the diffusivity.

\subsection{Wave Equation}
Here $u$ may represent the displacement from equilibrium; in electricity it may be the current or potential along a transmission line; or it may be a component of \textbf{E} or \textbf{B} in an electromagnetic wave.
The equation is written as
\begin{equation*}
    \nabla^2u=\frac{1}{v^2}\frac{\partial^2u}{\partial t^2}
\end{equation*}

\subsection{Helmholtz Equation}
Helmholtz's equation is the spatial part of either diffusion or wave equation
\begin{equation*}
    \nabla^2F+k^2F=0
\end{equation*}

\subsection{Schrödinger's Equation}
Also known as the wave function equation of quantum mechanics
\begin{equation*}
    -\frac{\hbar^2}{2m}\nabla^2\Psi+V\Psi= i\hbar\frac{\partial \Psi}{\partial t}
\end{equation*}
\end{document}