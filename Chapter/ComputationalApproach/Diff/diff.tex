\documentclass[../../../main.tex]{subfiles}
\begin{document}
\subsection{Courant Number}
The Courant number measures how far information (e.g., a fluid particle or wave front) travels across the grid during one time step relative to the grid spacing.
\begin{equation*}
    \sigma=\frac{u \Delta t}{\Delta x}
\end{equation*}
Numerical stability typically requires $\sigma<1$, and as such we can write the time steps $\Delta x$ as
\begin{equation*}
    \Delta t=\frac{\sigma \Delta x }{u}
\end{equation*}

For example, consider some loop at which time iteration is required.
In each iteration of our time loop, we use the existing data about our wave to estimate the speed of the wave in the subsequent time step.
What has happened is that over the time period $\Delta t$, the wave is travelling a distance which is greater than \verb|dx|.  The length \verb|dx| of each grid box is related to the number of total points \verb|nx|, so stability can be enforced if the $\Delta t$ step size is calculated with respect to the size of \verb|dx|.

\subsection{Finite Method}
\subsubsection{Forward difference.}
The forward difference of a function $f(x)$ with step size $h$ is defined as
\begin{equation*}
    \Delta f(x)=f(x+h)-f(x)
\end{equation*}
The corresponding approximation of the first derivative is
\begin{equation*}
    f'(x)\approx \frac{f(x+h )-f(x )}{h}
\end{equation*}
Forward difference uses data at the current and next point.

\subsubsection{Backward difference.}
The backward difference of a function $f(x)$ with step size $h$ is defined as
\begin{equation*}
    \nabla f(x)=f(x)-f(x-h)
\end{equation*}
The corresponding approximation of the first derivative is
\begin{equation*}
    f'(x)\approx \frac{f(x )-f(x-h )}{h}
\end{equation*}
Backward difference uses data at the current and previous point.

\subsubsection{Central difference.}
Denoted by
\begin{equation*}
    \delta f(x)=f(x+h/2)-f(x-h/2)
\end{equation*}
with the first derivative as
\begin{equation*}
    f'(x)\approx \frac{f(x+h/2)-f(x-h/2)}{h}
\end{equation*}
or equivalently
\begin{equation*}
    f'(x)\approx \frac{f(x+h)-f(x-h)}{2h}
\end{equation*}

\subsubsection{Taylor series relation.}
Recall the Taylor expansion of $f(x)$
\begin{equation*}
    f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n
\end{equation*}
Now expand $f(x+h)$ with Taylor expansion by substituting $x=a$ with $a$ as the expansion point
\begin{equation*}
    f(x+h) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x+h-a)^n= \sum_{n=0}^{\infty} \frac{f^{(n)}(x)}{n!}h^n
\end{equation*}
Now do the same thing for $f(x-h)$ instead
\begin{equation*}
    f(x+h) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-h-a)^n= \sum_{n=0}^{\infty} (-1)^n\frac{f^{(n)}(x)}{n!}h^n
\end{equation*}
Explicitly, both equation can be written
\begin{align*}
    f(x+h) & =  f(x) + h f'(x) + \frac{h^2}{2} f''(x) + \frac{h^3}{6} f^{(3)}(x) + \cdots \\
    f(x-h) & =  f(x) - h f'(x) + \frac{h^2}{2} f''(x) - \frac{h^3}{6} f^{(3)}(x) + \cdots
\end{align*}

To obtain forward difference, subtract $f(x+h)$ by $f(x)$ and divide by $h$
\begin{equation*}
    \frac{f(x+h) - f(x)}{h} = f'(x) + \frac{h}{2} f''(x) + \frac{h^2}{6} f^{(3)}(x) +\cdots
\end{equation*}
Thus
\begin{equation*}
    f'(x) \approx \frac{f(x+h) - f(x)}{h}, \quad \text{error } = O(h)
\end{equation*}

In order to obtain backward difference, subtract $f(x-h)$ by $f(x)$ and divide by $h$
\begin{equation*}
    \frac{f(x+h) - f(x)}{h} = f'(x) + \frac{h}{2} f''(x) + \frac{h^2}{6} f^{(3)}(x) +\cdots
\end{equation*}
Thus
\begin{equation*}
    f'(x) \approx \frac{f(x) - f(x-h)}{h}, \quad \text{error } = O(h).
\end{equation*}

To obtain central difference, subtract $f(x+h)$ by $f(x-h)$ and divide by $h$
\begin{equation*}
    f(x+h) - f(x-h) = 2h f'(x) + \frac{h^3}{3} f^{(3)}(x) +\cdots
\end{equation*}
then divide by $2h$
\begin{equation*}
    \frac{f(x+h) - f(x-h)}{2h} = f'(x) + \frac{h^2}{6} f^{(3)}(x) +\cdots
\end{equation*}
Thus
\begin{equation*}
    f'(x) \approx \frac{f(x+h) - f(x-h)}{2h}, \quad \text{error } = O(h^2)
\end{equation*}

\subsection{1D Linear Convection}
The equation is written as
\begin{equation*}
    \frac{\partial u}{\partial t} + c \frac{\partial u}{\partial x} = 0
\end{equation*}
Using forward difference for time and backward difference for spatial, our discrete equation is
\begin{equation*}
    \frac{u_i^{n+1}-u_i^n}{\Delta t} + c \frac{u_i^n - u_{i-1}^n}{\Delta x} = 0
\end{equation*}
Where $n$ and $n+1$ are two consecutive steps in time, while $i-1$ and $i$ are two neighboring points of the discretized $x$ coordinate.
If there are given initial conditions, then the only unknown in this discretization is $u_i^{n+1}$, which can be solved as
\begin{equation*}
    u_i^{n+1} = u_i^n - c \frac{\Delta t}{\Delta x}(u_i^n-u_{i-1}^n)
\end{equation*}

\subsubsection{Non-linear convection.}
The equation takes the form
\begin{equation*}
    \frac{\partial u}{\partial t} + u \frac{\partial u}{\partial x} = 0
\end{equation*}
Instead of a constant factor $c$ multiplying the second term, now we have the solution $u$ multiplying it, causing the equation to be non-linear.
As before, the discrete form is
\begin{equation*}
    \frac{u_i^{n+1}-u_i^n}{\Delta t} + u_i^n \frac{u_i^n-u_{i-1}^n}{\Delta x} = 0
\end{equation*}
or more practically written as
\begin{equation*}
    u_i^{n+1} = u_i^n - u_i^n \frac{\Delta t}{\Delta x} (u_i^n - u_{i-1}^n)
\end{equation*}

\subsubsection*{Implementation.}
Given the initial conditions, the solution can be written in python numerically, using the Courant number, as
\begin{minted}[breaklines]{python}
def linearconv(nx):
    dx = 2 / (nx - 1)
    nt = 20    #nt is the number of timesteps we want to calculate
    c = 1
    sigma = .5
    
    dt = sigma * dx

    u = numpy.ones(nx) 
    u[int(.5/dx):int(1 / dx + 1)] = 2

    un = numpy.ones(nx)

    for n in range(nt):  #iterate through time
        un = u.copy() ##copy the existing values of u into un
        for i in range(1, nx):
            u[i] = un[i] - c * dt / dx * (un[i] - un[i-1])
\end{minted}
and for the non-linear equation
\begin{minted}[breaklines]{python}
def nonlinear(nx):
    dx = 2 / (nx - 1)
    nt = 20    #nt is the number of timesteps we want to calculate
    c = 1
    sigma = .5
    
    dt = sigma * dx

    u = numpy.ones(nx) 
    u[int(.5/dx):int(1 / dx + 1)] = 2

    un = numpy.ones(nx)

    for n in range(nt):  #iterate through time
        un = u.copy() ##copy the existing values of u into un
        for i in range(1, nx):
           u[i] = un[i] - un[i] * dt / dx * (un[i] - un[i-1]) 
        
    pyplot.plot(numpy.linspace(0, 2, nx), u)
\end{minted}
As a bonus we can define the function where it begins with sinusoidal and after one period, it disappears
\begin{minted}[breaklines]{python}
def y(nx):
    u=numpy.zeros(nx)
    quarter=int(len(nx)/4)
    alpha = quarter / (2 * numpy.pi) 

    for i in range(0,quarter):
        u[i] = numpy.sin(i / alpha)
    return u
\end{minted}
Other is a simple step function
\begin{minted}[breaklines]{python}
def z(nx):
    u = numpy.zeros(nx) 
    quarter=int(len(nx)/4)
    half=int(len(nx)/2)
    u[quarter:half] = 1
\end{minted}

\subsection{1D Diffusion Equation}
The one-dimensional diffusion equation is
\begin{equation*}
    \frac{\partial u}{\partial t}= \nu \frac{\partial^2 u}{\partial x^2}
\end{equation*}
The discrete version is 
\begin{equation*}
    \frac{u_{i}^{n+1}-u_{i}^{n}}{\Delta t}=\nu\frac{u_{i+1}^{n}-2u_{i}^{n}+u_{i-1}^{n}}{\Delta x^2}
\end{equation*}
or 
\begin{equation*}
    u_{i}^{n+1}=u_{i}^{n}+\frac{\nu\Delta t}{\Delta x^2}(u_{i+1}^{n}-2u_{i}^{n}+u_{i-1}^{n})
\end{equation*}

\subsubsection*{Derivation.}
Consider the Taylor expansion of $u_{i+1}$ and $u_{i-1}$ around $u_i$
\begin{align*}
    u_{i+1} &=  u_i + \Delta x \frac{\partial u}{\partial x}\bigg|_i + \frac{\Delta x^2}{2} \frac{\partial ^2 u}{\partial x^2}\bigg|_i + \frac{\Delta x^3}{3!} \frac{\partial ^3 u}{\partial x^3}\bigg|_i + O(\Delta x^4)\\
    u_{i-1} &=  u_i - \Delta x \frac{\partial u}{\partial x}\bigg|_i + \frac{\Delta x^2}{2} \frac{\partial ^2 u}{\partial x^2}\bigg|_i - \frac{\Delta x^3}{3!} \frac{\partial ^3 u}{\partial x^3}\bigg|_i + O(\Delta x^4)
\end{align*}
Add both 
\begin{equation*}
    u_{i+1} + u_{i-1} = 2u_i+\Delta x^2 \frac{\partial ^2 u}{\partial x^2}\bigg|_i + O(\Delta x^4)
\end{equation*}
And rearrange thing 
\begin{equation*}
    \frac{\partial ^2 u}{\partial x^2}=\frac{u_{i+1}-2u_{i}+u_{i-1}}{\Delta x^2} + O(\Delta x^2)
\end{equation*}
Now we can write the discretized diffusion equation
\begin{equation*}
    \frac{u_{i}^{n+1}-u_{i}^{n}}{\Delta t}=\nu\frac{u_{i+1}^{n}-2u_{i}^{n}+u_{i-1}^{n}}{\Delta x^2}
\end{equation*}
or 
\begin{equation*}
    u_{i}^{n+1}=u_{i}^{n}+\frac{\nu\Delta t}{\Delta x^2}(u_{i+1}^{n}-2u_{i}^{n}+u_{i-1}^{n})
\end{equation*}

\subsubsection*{Implementiation.}
In python
\begin{minted}[breaklines]{python}
def diffus(u,nt,CFL):
    nx=len(u)
    dx = 2 / (nx - 1)
    nu = 0.3   
    sigma=CFL
    dt = sigma * dx**2 / nu 
    un=numpy.zeros(nx)
    for i in range(1,nt):
        un=u.copy()
        for j in range(1,nx-1):
            u[j]=un[j]+nu*dt/dx**2*(u[j+1]-2*u[j]+u[j-1])
    return u
\end{minted}

\subsection{2D Diffusion Equation}
In two-dimensional, we have
\begin{equation*}
\frac{\partial u}{\partial t} = \nu \left( 
\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} 
\right)
\end{equation*}
Similar like the 1D counterpart, we only need to add the second spatial direction
\begin{equation*}
\frac{u_{i,j}^{\,n+1} - u_{i,j}^{\,n}}{\Delta t} 
= \nu \left(
\frac{u_{i+1,j}^{\,n} - 2 u_{i,j}^{\,n} + u_{i-1,j}^{\,n}}{\Delta x^2} 
+ \frac{u_{i,j+1}^{\,n} - 2 u_{i,j}^{\,n} + u_{i,j-1}^{\,n}}{\Delta y^2} 
\right)
\end{equation*}
or 
\begin{equation*}
u_{i,j}^{\,n+1} = u_{i,j}^{\,n} + \nu \Delta t \left[
\frac{u_{i+1,j}^{\,n} - 2 u_{i,j}^{\,n} + u_{i-1,j}^{\,n}}{\Delta x^2} 
+ \frac{u_{i,j+1}^{\,n} - 2 u_{i,j}^{\,n} + u_{i,j-1}^{\,n}}{\Delta y^2}
\right]
\end{equation*}
To make the computation easier, the diffusion constant is often used
\begin{equation*}
    \alpha_i =\nu \frac{\Delta t }{\Delta i^2}
\end{equation*}

\subsubsection{Implementiation.} As before.
\begin{minted}[breaklines]{python}
def diffus_2D(u,nt,alpha):
    nx = len(u)       
    ny = len(u[0])    
    dx = 2 / (nx - 1)
    dy = 2 / (ny - 1)

    un=numpy.zeros_like(u)
    for i in range(nt):
        un=u.copy()
        for j in range(1,nx-1):
            for k in range(1,ny-1):
                u[j,k]=un[j,k]+alpha*(un[j+1,k]-2*un[j,k]+un[j-1,k]+un[j,k+1]-2*un[j,k]+un[j,k-1])
    return u
\end{minted}

\subsection{1D Burgers's Equation}
Burgers' equation is a combination of non-linear convection and diffusion, which in one spatial dimension looks like this
\begin{equation*}
    \frac{\partial u}{\partial t} + u \frac{\partial u}{\partial x} = \nu \frac{\partial ^2u}{\partial x^2}
\end{equation*}
The analytic solution is given by 
\begin{gather*}
    u= -\frac{2 \nu}{\phi} \frac{\partial \phi}{\partial x} + 4 \\
    \phi = \exp \bigg(\frac{-(x-4t)^2}{4 \nu (t+1)} \bigg) + \exp \bigg(\frac{-(x-4t -2 \pi)^2}{4 \nu(t+1)} \bigg)
\end{gather*}
with initial conditions of 
\begin{gather*}
    u = -\frac{2 \nu}{\phi} \frac{\partial \phi}{\partial x} + 4 \\
    \phi = \exp \bigg(\frac{-x^2}{4 \nu} \bigg) + \exp \bigg(\frac{-(x-2 \pi)^2}{4 \nu} \bigg)
\end{gather*}
and periodic boundary conditions of $u(0)=u(2\pi)$.

The discretized version is 
\begin{equation*}
    \frac{u_i^{n+1}-u_i^n}{\Delta t} + u_i^n \frac{u_i^n - u_{i-1}^n}{\Delta x} = \nu \frac{u_{i+1}^n - 2u_i^n + u_{i-1}^n}{\Delta x^2}
\end{equation*}
or 
\begin{equation*}
    u_i^{n+1} = u_i^n - u_i^n \frac{\Delta t}{\Delta x} (u_i^n - u_{i-1}^n) + \nu \frac{\Delta t}{\Delta x^2}(u_{i+1}^n - 2u_i^n + u_{i-1}^n)
\end{equation*}
\end{document}